{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d77636",
   "metadata": {},
   "source": [
    "## Luminance-only LGN circuits -- GPU1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ce43cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T21:12:17.955328Z",
     "start_time": "2023-07-07T21:12:17.883430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Computer: [ca1]\n",
      "Save_dir = /home/dbutts/ColorV1/CLRworkspace/\n",
      "cuda:1\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './')\n",
    "\n",
    "import os\n",
    "import h5py \n",
    "\n",
    "# setup paths\n",
    "iteration = 1 # which version of this tutorial to run (in case want results in different dirs)\n",
    "NBname = 'color_cloud_initial{}'.format(iteration)\n",
    "\n",
    "myhost = os.uname()[1] # get name of machine\n",
    "print(\"Running on Computer: [%s]\" %myhost)\n",
    "\n",
    "if myhost=='hoser':\n",
    "    sys.path.insert(0, '/Users/dbutts/')\n",
    "    dirname = os.path.join('.', 'checkpoints')\n",
    "    datadir = '/Users/dbutts/V1/Conway/'\n",
    "else:\n",
    "    #sys.path.insert(0, '/home/dbutts/Code/') \n",
    "    datadir = '/home/dbutts/ColorV1/Data/'  \n",
    "    dirname = '/home/dbutts/ColorV1/CLRworkspace/' # Working directory \n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from copy import deepcopy\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# NDN tools\n",
    "import NDNT.utils as utils # some other utilities\n",
    "import NDNT.NDNT as NDN\n",
    "from NDNT.modules.layers import *\n",
    "from NDNT.networks import *\n",
    "from time import time\n",
    "import dill\n",
    "\n",
    "from NTdatasets.generic import GenericDataset\n",
    "import NTdatasets.conway.cloud_datasets as datasets\n",
    "\n",
    "# Utilities\n",
    "import ColorDataUtils.ConwayUtils as CU\n",
    "import ColorDataUtils.EyeTrackingUtils as ETutils\n",
    "from NDNT.utils import imagesc   # because I'm lazy\n",
    "from NDNT.utils import ss        # because I'm real lazy\n",
    "\n",
    "from ColorDataUtils import mattplotlib as mplt\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device0 = torch.device(\"cpu\")\n",
    "dtype = torch.float32\n",
    "\n",
    "# Where saved models and checkpoints go -- this is to be automated\n",
    "print( 'Save_dir =', dirname)\n",
    "print(device)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3229dc19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T21:13:58.856203Z",
     "start_time": "2023-07-07T21:12:18.077186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing stimulus channels (3) to first dimension\n",
      "Loading data into memory...\n",
      "Adjusting stimulus read from disk: mean | std = -0.000 | 0.269\n",
      "T-range: 0 167520\n",
      "  Trimming experiment 365280->167520 time points based on eye_config and Tmax\n",
      "100.45890522003174 sec elapsed\n",
      "167520 (167520 valid) time points\n",
      "29 laminar units, 210 ET units\n",
      "  Redoing fix_n with saccade inputs: 6827 saccades\n",
      "3795 fixations\n"
     ]
    }
   ],
   "source": [
    "# Load data (all stim)\n",
    "fn = 'Jocamo_220715_full_CC_ETCC_nofix_v08'\n",
    "num_lags=16\n",
    "\n",
    "t0 = time()\n",
    "data = datasets.ColorClouds(\n",
    "    datadir=datadir, filenames=[fn], eye_config=3, drift_interval=16, \n",
    "    luminance_only=True, binocular=False, include_MUs=True, num_lags=num_lags,\n",
    "    trial_sample=True)\n",
    "t1 = time()\n",
    "print(t1-t0, 'sec elapsed')\n",
    "\n",
    "NT = data.robs.shape[0]\n",
    "NA = data.Xdrift.shape[1]\n",
    "print(\"%d (%d valid) time points\"%(NT, len(data)))\n",
    "#data.valid_inds = np.arange(NT, dtype=np.int64)\n",
    "\n",
    "lam_units = np.where(data.channel_map < 32)[0]\n",
    "ETunits = np.where(data.channel_map >= 32)[0]\n",
    "UTunits = np.where(data.channel_map >= 32+127)[0]\n",
    "\n",
    "print( \"%d laminar units, %d ET units\"%(len(lam_units), len(ETunits)))\n",
    "\n",
    "# Replace DFs\n",
    "matdat = sio.loadmat(datadir+'Jocamo_220715_full_CC_ETCC_nofix_v08_DFextra.mat')\n",
    "data.dfs = torch.tensor( matdat['XDF'][:NT, :], dtype=torch.float32 )\n",
    "\n",
    "# Pull correct saccades\n",
    "matdat = sio.loadmat( datadir+'Jocamo_220715_full_CC_ETCC_v08_ETupdate.mat')\n",
    "sac_ts_all = matdat['ALLsac_bins'][0, :]\n",
    "\n",
    "data.process_fixations( sac_ts_all )\n",
    "sac_tsB = matdat['sac_binsB'][0, :]\n",
    "sac_tsL = matdat['sac_binsL'][0, :]\n",
    "sac_tsR = matdat['sac_binsR'][0, :]\n",
    "\n",
    "NFIX = torch.max(data.fix_n).detach().numpy() \n",
    "print(NFIX, 'fixations')\n",
    "et1kHzB = matdat['et1kHzB']\n",
    "et60B = matdat['et60HzB']\n",
    "et60all = matdat['et60Hz_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ac7d137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T21:13:58.946132Z",
     "start_time": "2023-07-07T21:13:58.858898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 out of 195 units used\n",
      "Output set to 174 cells\n"
     ]
    }
   ],
   "source": [
    "# Set cells-to-analyze and pull best model configuration and mus\n",
    "Reff = torch.mul(data.robs[:, UTunits], data.dfs[:, UTunits]).numpy()\n",
    "nspks = np.sum(Reff, axis=0)\n",
    "a = np.where(nspks > 10)[0]\n",
    "valET = UTunits[a]\n",
    "NCv = len(valET)\n",
    "print(\"%d out of %d units used\"%(len(valET), len(UTunits)))\n",
    "\n",
    "## CONVERT LLsNULL, which is based on \n",
    "\n",
    "# Read in previous data\n",
    "dirname2 = dirname+'0715/et/'\n",
    "matdat = sio.loadmat(dirname2+'LLsGLM.mat')\n",
    "Dreg = matdat['Dreg']\n",
    "top_corner = matdat['top_corner'][:, 0]\n",
    "\n",
    "adam_pars = utils.create_optimizer_params(\n",
    "    optimizer_type='AdamW', batch_size=2000, num_workers=0,\n",
    "    learning_rate=0.01, early_stopping_patience=6,  # changed from 4\n",
    "    optimize_graph=False, weight_decay = 0.2)\n",
    "adam_pars['device'] = device\n",
    "\n",
    "data.set_cells(valET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8374c5fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T21:14:46.343060Z",
     "start_time": "2023-07-07T21:13:58.938299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stim expansion for shift: [900, 492, 1000, 592]\n",
      "  Writing lam stim 0: overlap 60, 47\n",
      "  Writing lam stim 1: overlap 60, 53\n",
      "  Writing lam stim 2: overlap 33, 53\n",
      "  Writing lam stim 3: overlap 33, 47\n",
      "  Writing ETstim 0: overlap 7, 53\n",
      "  Writing ETstim 1: overlap 7, 47\n",
      "  Adding fixation point\n",
      "  Shifting stim...\n",
      "  CROP: New stim size: 60 x 60\n",
      "  Done\n"
     ]
    }
   ],
   "source": [
    "# Load shifts and previous models\n",
    "dirname2 = dirname+'0715/et/'\n",
    "SHfile = sio.loadmat( dirname2 + 'BDshifts1.mat' )\n",
    "fix_n = SHfile['fix_n']\n",
    "shifts = SHfile['shifts']\n",
    "metricsLL = SHfile['metricsLL']\n",
    "metricsTH = SHfile['metricsTH']\n",
    "ETshifts = SHfile['ETshifts']\n",
    "ETmetrics = SHfile['ETmetrics']\n",
    "Ukeeps = SHfile['Ctrain']\n",
    "XVkeeps = SHfile['Cval']\n",
    "\n",
    "# Make 60x60 STAs (and GLMs)\n",
    "Xshift = 14 #8+4 \n",
    "Yshift = -3 #-10+4\n",
    "NX = 60\n",
    "\n",
    "new_tc = np.array([top_corner[0]-Xshift, top_corner[1]-Yshift], dtype=np.int64)\n",
    "data.draw_stim_locations(top_corner = new_tc, L=NX)\n",
    "\n",
    "data.assemble_stimulus(top_corner=[new_tc[0], new_tc[1]], L=NX, fixdot=0, shifts=-shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7873958c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T21:14:46.434818Z",
     "start_time": "2023-07-07T21:14:46.343881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.5% fixations remaining\n"
     ]
    }
   ],
   "source": [
    "goodfix = np.where(ETmetrics[:,1] < 0.80)[0]\n",
    "valfix = torch.zeros([ETmetrics.shape[0], 1], dtype=torch.float32)\n",
    "valfix[goodfix] = 1.0\n",
    "# Test base-level performance (full DFs and then modify DFs)\n",
    "#DFsave = deepcopy(data2.dfs)  # this is also in data.dfs\n",
    "data.dfs_out *= valfix\n",
    "print(\"%0.1f%% fixations remaining\"%(100*len(goodfix)/ETmetrics.shape[0]))\n",
    "\n",
    "lbfgs_pars = utils.create_optimizer_params(\n",
    "    optimizer_type='lbfgs',\n",
    "    tolerance_change=1e-8,\n",
    "    tolerance_grad=1e-8,\n",
    "    history_size=100,\n",
    "    batch_size=20,\n",
    "    max_epochs=3,\n",
    "    max_iter = 500,\n",
    "    device = device)\n",
    "\n",
    "adam_parsT = utils.create_optimizer_params(\n",
    "    optimizer_type='AdamW', batch_size=4, num_workers=0,\n",
    "    learning_rate=0.01, early_stopping_patience=10,  # changed from 4\n",
    "    optimize_graph=False, weight_decay = 0.2)\n",
    "adam_parsT['device'] = device\n",
    "adam_parsT['accumulated_grad_batches'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d90b9696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T21:14:46.448723Z",
     "start_time": "2023-07-07T21:14:46.363131Z"
    }
   },
   "outputs": [],
   "source": [
    "dirname2 = dirname+'0715/NewGLMs/'\n",
    "matdat = sio.loadmat(dirname2+'J0715ProcGLMinfo.mat')\n",
    "LLsNULL = matdat['LLsNULL'][:,0]\n",
    "LLsGLM = matdat['LLsGLM'][:,0]\n",
    "LLsGLM2 = matdat['LLsGLM2'][:,0]\n",
    "drift_terms = matdat['drift_terms']\n",
    "valET = matdat['cells'] \n",
    "RFcenters = matdat['RFcenters']\n",
    "#'Gregs': Gopt[:,None], 'XTregs': Xopt\n",
    "#'top_corner': new_tc[:, None]})\n",
    "mu0s = utils.pixel2grid(deepcopy(RFcenters[:, [1, 0]]), L=NX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d6bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_readout_display(w, start_n, num_subs, inh_frac):\n",
    "    NF, NC = w.shape\n",
    "    num_layers = (NF-start_n)//num_subs\n",
    "    assert num_layers == (NF-start_n)/num_subs, \"something wrong %f\"%(NF-start_n)/num_subs\n",
    "    NE = num_subs-num_subs//inh_frac\n",
    "    for ii in range(num_layers):\n",
    "        w[start_n+num_subs*ii+np.arange(NE, num_subs), :] *= -1\n",
    "    ss(rh=8)\n",
    "    imagesc(w, cmap='bwr')\n",
    "    for ii in range(num_layers):\n",
    "        plt.plot(np.ones(2)*(start_n-0.5)+ii*num_subs, [-0.5, NC-0.5],'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841e0e26",
   "metadata": {},
   "source": [
    "## LGN LUMINANCE MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "LGNlags = 11\n",
    "LGNsubs = 4\n",
    "fw0 = 7\n",
    "\n",
    "proj_width = 17\n",
    "\n",
    "Treg = 0.01\n",
    "Xreg = 0.000001\n",
    "Mreg = 0.0001\n",
    "Creg = None\n",
    "Dreg = 0.5\n",
    "Gnet = 0.005\n",
    "\n",
    "num_iter = 4\n",
    "num_subs = 30\n",
    "fwI = 7\n",
    "\n",
    "\n",
    "LGNpars = STconvLayer.layer_dict( \n",
    "    input_dims = data.stim_dims, num_filters=LGNsubs, bias=False, norm_type=1,\n",
    "    filter_dims=[1,fw0,fw0,LGNlags] , NLtype='relu', initialize_center=True)\n",
    "LGNpars['output_norm']='batch'\n",
    "LGNpars['window']='hamming'\n",
    "LGNpars['reg_vals'] = {'d2x':Xreg, 'd2t':Treg, 'center': Creg, 'edge_t':100}  \n",
    "\n",
    "proj_pars = ConvLayer.layer_dict( \n",
    "    num_filters=num_subs, bias=False, norm_type=1, num_inh=num_subs//2,\n",
    "    filter_dims=proj_width, NLtype='lin', initialize_center=True)\n",
    "proj_pars['output_norm']='batch'\n",
    "proj_pars['window']='hamming'\n",
    "\n",
    "Ilayers = IterSTlayer.layer_dict(    \n",
    "    num_filters=num_subs, bias=False, num_iter=num_iter, output_config='full',\n",
    "    pos_constraint=True,\n",
    "    norm_type=1, num_inh=num_subs//2, filter_width=fwI, num_lags=2, \n",
    "    NLtype='relu', initialize_center=False) \n",
    "Ilayers['output_norm'] = 'batch'\n",
    "# Ilayers['reg_vals'] = {'glocal': Gnet}  \n",
    "        \n",
    "scaffold_net =  FFnetwork.ffnet_dict(\n",
    "    ffnet_type='scaffold', xstim_n = 'stim', layer_list=[LGNpars, proj_pars, Ilayers], scaffold_levels=[1,2] )\n",
    "\n",
    "## 1: READOUT\n",
    "readout_pars = ReadoutLayer.layer_dict(\n",
    "    num_filters=NCv, NLtype='lin', bias=False, pos_constraint=True)\n",
    "readout_pars['gauss_type'] = 'isotropic'\n",
    "readout_pars['reg_vals'] = {'max': Mreg} \n",
    "\n",
    "readout_net = FFnetwork.ffnet_dict( \n",
    "    xstim_n = None, ffnet_n=[0],\n",
    "    layer_list = [readout_pars], ffnet_type='readout')\n",
    "\n",
    "## 2: DRIFT\n",
    "drift_pars = NDNLayer.layer_dict( \n",
    "    input_dims=[1,1,1,NA], num_filters=NCv, bias=False, norm_type=0, NLtype='lin')\n",
    "drift_pars['reg_vals'] = {'d2t': Dreg } \n",
    "\n",
    "drift_net =  FFnetwork.ffnet_dict( xstim_n = 'Xdrift', layer_list = [drift_pars] )\n",
    "\n",
    "## 3: COMB \n",
    "comb_layer = ChannelLayer.layer_dict(\n",
    "    num_filters = NCv, NLtype='softplus', bias=True)\n",
    "comb_layer['weights_initializer'] = 'ones'\n",
    "\n",
    "comb_net = FFnetwork.ffnet_dict( \n",
    "    xstim_n = None, ffnet_n=[1,2],\n",
    "    layer_list = [comb_layer], ffnet_type='add')\n",
    "\n",
    "\n",
    "## LESS ITERATIONS AND LINEAR PROJECTION LAYER (!)\n",
    "\n",
    "LGNmods = []\n",
    "cnn_iter = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "cnn_iter.block_sample = True\n",
    "\n",
    "## Network 1: readout: fixed mus / sigmas\n",
    "cnn_iter.networks[1].layers[0].sample = False\n",
    "#cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "cnn_iter.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "cnn_iter.networks[1].set_parameters(val=False, name='mu')\n",
    "cnn_iter.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "## Network 2: drift: not fit\n",
    "cnn_iter.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "cnn_iter.networks[2].set_parameters(val=False)\n",
    "\n",
    "## Network 3: Comb\n",
    "cnn_iter.networks[-1].set_parameters(val=False, name='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "588a4014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T21:12:05.262188Z",
     "start_time": "2023-07-07T21:11:58.446926Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No version requested. Using (best) version (v=19)\n"
     ]
    }
   ],
   "source": [
    "cnn = NDN.NDN.load_model('./checkpoints', 'M174_CsCX_R_N_A')\n",
    "#LLs = cnn.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "#print(np.mean(LLsNULL-LLs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad2ebf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cnn.fit( data, **adam_parsT, verbose=2)\n",
    "LLs = cnn.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "print(np.mean(LLsNULL-LLs))\n",
    "LLsLGN = deepcopy(LLsNULL-LLs)\n",
    "LGNmods.append(deepcopy(cnn_iter))\n",
    "\n",
    "# pickle model\n",
    "with open('models/dan/cnn.pkl', 'wb') as f:\n",
    "    pickle.dump(cnn, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a2350",
   "metadata": {},
   "source": [
    "### matt analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add80989",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "cnn.plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ab352",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23d900",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients, NeuronIntegratedGradients, Saliency, DeepLift, NoiseTunnel, NeuronDeepLift\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "ind = 200\n",
    "# combine the inputs going in, and split into dictionary when passing to the model\n",
    "def stim_layer(inpu):\n",
    "    stim_inp = inpu[:,0:3600]\n",
    "    Xdrift_inp = inpu[:,3600:]\n",
    "    return cnn.networks[0].layers[0](stim_inp)\n",
    "\n",
    "def stimq_layer(inpu):\n",
    "    stim_inp = inpu[:,0:3600]\n",
    "    Xdrift_inp = inpu[:,3600:]\n",
    "    return cnn.networks[2].layers[0](stim_inp)\n",
    "\n",
    "def net(inpu):\n",
    "    stim_inp = inpu[:,0:3600]\n",
    "    Xdrift_inp = inpu[:,3600:]\n",
    "    return cnn({'stim':stim_inp, 'Xdrift':Xdrift_inp})\n",
    "\n",
    "def net_zero(inpu):\n",
    "    cnn.zero_grad()\n",
    "    return net(inpu)\n",
    "\n",
    "inps = torch.hstack([data.stim[data.val_inds,:], data.Xdrift[data.val_inds,:]])\n",
    "robs = data.robs[data.val_inds,:]*data.dfs[data.val_inds,:]\n",
    "\n",
    "inps.shape, robs.shape, data.NC\n",
    "\n",
    "# inp = inps[ind].unsqueeze(0)\n",
    "# inp.requires_grad = True\n",
    "# rob = robs[ind].unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "#pred = net(inp)\n",
    "\n",
    "#net_zero(inp).shape\n",
    "#inp.shape, rob, data.robs.shape, data[ind]['Xdrift'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b86c951",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cnn.networks[-1].layers[-1].output_dims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f30001a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3cd419c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T21:54:19.611919Z",
     "start_time": "2023-07-07T21:54:19.544063Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   3   4   5   6   8   9  10  11  13  14  15  16  18  19  20  21\n",
      "  23  24  25  26  28  29  30  31  33  34  35  36  38  39  40  41  43  44\n",
      "  45  46  48  49  50  51  53  54  55  56  58  59  60  61  63  64  65  66\n",
      "  68  69  70  71  73  74  75  76  78  79  80  81  83  84  85  86  88  89\n",
      "  90  91  93  94  95  96  98  99 100 101 103 104 105 106 108 109 110 111\n",
      " 113 114 115 116 118 119 120 121 123 124 125 126 128 129 130 131 133 134\n",
      " 135 136 138 139 140 141 143 144 145 146 148 149 150 151 153 154 155 156\n",
      " 158 159 160 161 163 164 165 166 168 169 170 171 173 174 175 176 178 179\n",
      " 180 181 183 184 185 186 188 189 190 191 193 194 195 196 198 199 200 201\n",
      " 203 204 205 206 208 209 210 211 213 214 215 216 218 219 220 221 223 224\n",
      " 225 226 228 229 230 231 233 234 235 236 238 239 240 241 243 244 245 246\n",
      " 248 249 250 251 253 254 255 256 258 259 260 261 263 264 265 266 268 269\n",
      " 270 271 273 274 275 276 278 279 280 281 283 284 285 286 288 289 290 291\n",
      " 293 294 295 296 298 299 300 301 303 304 305 306 308 309 310 311 313 314\n",
      " 315 316 318 319 320 321 323 324 325 326 328 329 330 331 333 334 335 336\n",
      " 338 339 340 341 343 344 345 346 348 349 350 351 353 354 355 356 358 359\n",
      " 360 361 363 364 365 366 368 369 370 371 373 374 375 376 378 379 380 381\n",
      " 383 384 385 386 388 389 390 391 393 394 395 396 398 399 400 401 403 404\n",
      " 405 406 408 409 410 411 413 414 415 416 418 419 420 421 423 424 425 426\n",
      " 428 429 430 431 433 434 435 436 438 439 440 441 443 444 445 446 448 449\n",
      " 450 451 453 454 455 456 458 459 460 461 463 464 465 466 468 469 470 471\n",
      " 473 474 475 476 478 479 480 481 483 484 485 486 488 489 490 491 493 494\n",
      " 495 496 498 499 500 501 503 504 505 506 508 509 510 511 513 514 515 516\n",
      " 518 519 520 521 523 524 525 526 528 529 530 531 533 534 535 536 538 539\n",
      " 540 541 543 544 545 546 548 549 550 551 553 554 555 556 558 559 560 561\n",
      " 563 564 565 566 568 569 570 571 573 574 575 576 578 579 580 581 583 584\n",
      " 585 586 588 589 590 591 593 594 595 596 598 599 600 601 603 604 605 606\n",
      " 608 609 610 611 613 614 615 616 618 619 620 621 623 624 625 626 628 629\n",
      " 630 631 633 634 635 636 638 639 640 641 643 644 645 646 648 649 650 651\n",
      " 653 654 655 656 658 659 660 661 663 664 665 666 668 669 670 671 673 674\n",
      " 675 676 678 679 680 681 683 684 685 686 688 689 690 691 693 694 695 696]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647\n",
      " 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665\n",
      " 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683\n",
      " 684 685 686 687 688 689 690 691 692 693 694 695 696 697]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(data.block_inds), len(data.val_blks), len(data.train_blks), len(np.arange(len(data.block_inds)))\n",
    "\n",
    "print(data.train_blks), print(np.arange(len(data.block_inds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f11924fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T22:12:39.716247Z",
     "start_time": "2023-07-07T22:01:41.916895Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval models: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 35/35 [10:57<00:00, 18.79s/it]\n"
     ]
    }
   ],
   "source": [
    "pred = cnn.generate_predictions(data, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1581694d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T22:39:49.321459Z",
     "start_time": "2023-07-07T22:39:49.261756Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4800, 174])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pred.shape, data.robs.shape, cnn.ffnet_out\n",
    "#cnn.networks[cnn.ffnet_out[0]].output_dims[0]\n",
    "\n",
    "pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cda9b3d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T22:40:07.217229Z",
     "start_time": "2023-07-07T22:40:07.157708Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pred_torch = torch.vstack(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a526505f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T22:40:10.513564Z",
     "start_time": "2023-07-07T22:40:10.467564Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([167520, 174])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff31af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T21:12:07.420883Z",
     "start_time": "2023-07-07T21:12:07.345185Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     pred \u001b[38;5;241m=\u001b[39m cnn(data[:\u001b[38;5;241m200\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = cnn(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c99e4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-07T20:49:20.244948Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#data.robs = pred\n",
    "pred.shape, data.robs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7c5e2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# add pred to the dataset\n",
    "data.add_covariate('pred', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbfa84",
   "metadata": {},
   "source": [
    "### fit GLM and GQM on the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7929435",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#set up fits\n",
    "Treg = 1\n",
    "Xreg = 20 # [20]\n",
    "L1reg = 0.1 # [0.5]\n",
    "GLreg = 10.0 # [4.0]\n",
    "\n",
    "# drift network\n",
    "drift_pars1 = NDNLayer.layer_dict(\n",
    "    input_dims=[1,1,1,NA], num_filters=1, bias=False, norm_type=0, NLtype='lin')\n",
    "drift_pars1['reg_vals'] = {'d2t': Dreg, 'bcs':{'d2t':0} }\n",
    "# for stand-alone drift model\n",
    "drift_pars1N = deepcopy(drift_pars1)\n",
    "drift_pars1N['NLtype'] = 'softplus'\n",
    "drift_net =  FFnetwork.ffnet_dict( xstim_n = 'Xdrift', layer_list = [drift_pars1] )\n",
    "\n",
    "# glm net\n",
    "glm_layer = Tlayer.layer_dict(\n",
    "    input_dims=data.stim_dims, num_filters=1, bias=False, num_lags=num_lags,\n",
    "    NLtype='lin', initialize_center = True)\n",
    "glm_layer['reg_vals'] = {'d2x': Xreg, 'd2t': Treg, 'l1': L1reg, 'glocalx': GLreg,'edge_t':10}\n",
    "stim_net =  FFnetwork.ffnet_dict( xstim_n = 'stim', layer_list = [glm_layer] )\n",
    "\n",
    "# gqm net\n",
    "num_subs = 2\n",
    "gqm_layer = Tlayer.layer_dict(\n",
    "    input_dims=data.stim_dims, num_filters=num_subs, num_inh=0, bias=False, num_lags=num_lags,\n",
    "    NLtype='square', initialize_center = True)\n",
    "gqm_layer['reg_vals'] = {'d2x': Xreg, 'd2t': Treg, 'l1': L1reg, 'glocalx': GLreg,'edge_t':10}\n",
    "stim_qnet =  FFnetwork.ffnet_dict( xstim_n = 'stim', layer_list = [gqm_layer] )\n",
    "\n",
    "#combine glm\n",
    "comb_layer = NDNLayer.layer_dict(\n",
    "    num_filters = 1, NLtype='softplus', bias=False)\n",
    "comb_layer['weights_initializer'] = 'ones'\n",
    "\n",
    "net_comb = FFnetwork.ffnet_dict(\n",
    "    xstim_n = None, ffnet_n=[0,1],\n",
    "    layer_list = [comb_layer], ffnet_type='add')\n",
    "\n",
    "#combine gqm\n",
    "comb2_layer = ChannelLayer.layer_dict(\n",
    "    num_filters = 1, NLtype='softplus', bias=False)\n",
    "comb2_layer['weights_initializer'] = 'ones'\n",
    "\n",
    "net2_comb = FFnetwork.ffnet_dict(\n",
    "    xstim_n = None, ffnet_n=[0,1,2],\n",
    "    layer_list = [comb2_layer], ffnet_type='normal')\n",
    "net2_comb['layer_list'][0]['bias'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008b89a8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "matt_glms = []\n",
    "for cc in range(NCv):\n",
    "    glm_filename = 'models/optim/matt_glm_cc'+str(cc)+'.pkl'\n",
    "\n",
    "    drift_weights = matt_drifts[cc].ndn_model.networks[0].layers[0].weight.data[:,0]\n",
    "\n",
    "    # # continue if the file already exists\n",
    "    if os.path.isfile(glm_filename):\n",
    "        # load the model and continue\n",
    "        print('loading model', cc)\n",
    "        with open(glm_filename, 'rb') as f:\n",
    "            matt_glms.append(pickle.load(f))\n",
    "        continue\n",
    "\n",
    "    data.set_cells([vallam[cc]])\n",
    "\n",
    "    LLsNULL_cc = matt_drifts[cc].LLs\n",
    "\n",
    "    matt_glm = NDN.NDN(ffnet_list = [stim_net, drift_net, net_comb], loss_type='poisson')\n",
    "    matt_glm.block_sample=True\n",
    "    matt_glm.networks[1].layers[0].weight.data[:,0] = deepcopy(drift_weights)\n",
    "    matt_glm.networks[1].layers[0].set_parameters(val=False)\n",
    "    matt_glm.networks[2].layers[0].set_parameters(val=False,name='weight')\n",
    "\n",
    "    matt_glms_temp = []\n",
    "\n",
    "    def objective(trial):\n",
    "        lbfgs_pars = utils.create_optimizer_params(\n",
    "            optimizer_type='lbfgs',\n",
    "            tolerance_change=1e-10*trial.suggest_int('tolerance_change', 10, 1e6, log=True),\n",
    "            tolerance_grad=1e-10*trial.suggest_int('tolerance_grad', 10, 1e6, log=True),\n",
    "            history_size=100,\n",
    "            batch_size=20,\n",
    "            max_epochs=3,\n",
    "            max_iter = 500,\n",
    "            device = device)\n",
    "\n",
    "        matt_glm.networks[0].layers[0].reg.vals['d2x'] = 1e-5*trial.suggest_int('d2x', 10, 1e10, log=True)\n",
    "        matt_glm.networks[0].layers[0].reg.vals['d2t'] = 1e-5*trial.suggest_int('d2t', 10, 1e10, log=True)\n",
    "        matt_glm.networks[0].layers[0].reg.vals['d2xt'] = 1e-5*trial.suggest_int('d2xt', 10, 1e10, log=True)\n",
    "        matt_glm.networks[0].layers[0].reg.vals['l1'] = 1e-5*trial.suggest_int('l1', 10, 1e10, log=True)\n",
    "        matt_glm.networks[0].layers[0].reg.vals['glocalx'] = 1e-5*trial.suggest_int('glocalx', 10, 1e10, log=True)\n",
    "        matt_glm.networks[0].layers[0].reg.vals['edge_t'] = 1e-5*trial.suggest_int('edge_t', 10, 1e10, log=True)\n",
    "\n",
    "        matt_glm.fit( data, force_dict_training=True, trial=trial, **lbfgs_pars)\n",
    "        LL = matt_glm.eval_models(data[data.val_blks], null_adjusted=False)[0]\n",
    "\n",
    "        glm_model = Model(matt_glm, LLsNULL_cc-LL, trial)\n",
    "        matt_glms_temp.append(glm_model)\n",
    "\n",
    "        return LLsNULL_cc-LL\n",
    "\n",
    "    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.HyperbandPruner())\n",
    "\n",
    "    # enqueue initial parameters\n",
    "    # study.enqueue_trial(\n",
    "    #     {'d2t': 1,\n",
    "    #      'd2x': 20,\n",
    "    #      'l1': 0.1,\n",
    "    #      'glocalx': 10.0,\n",
    "    #      'edge_t': 10,\n",
    "    #      'tolerance_change': 1e-8,\n",
    "    #      'tolerance_grad': 1e-8})\n",
    "\n",
    "    study.optimize(objective, n_trials=15)\n",
    "\n",
    "    matt_glms.append(matt_glms_temp[study.best_trial.number])\n",
    "\n",
    "    with open(glm_filename, 'wb') as f:\n",
    "        matt_glms[cc].trial = study\n",
    "        pickle.dump(matt_glms[cc], f)\n",
    "\n",
    "    print(study.best_trial.number, study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90effaf2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637cc995",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3cf9d1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cea88614",
   "metadata": {},
   "source": [
    "### Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e68dda",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "num_cols = 4\n",
    "num_rows = 4\n",
    "\n",
    "# make a grid for the images\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "grid = matplotlib.gridspec.GridSpec(num_rows, num_cols)\n",
    "\n",
    "for i in range(16):\n",
    "    row,col = np.unravel_index(i, (num_rows, num_cols))\n",
    "    ax = plt.subplot(grid[row,col])\n",
    "    \n",
    "    # find the ind with the most spikes\n",
    "    ind = np.argmax(robs[:,i])\n",
    "    \n",
    "    inp = inps[ind].unsqueeze(0)\n",
    "    inp.requires_grad = True\n",
    "    rob = robs[ind,i].unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    original_image = inp[:, :3600].squeeze().cpu().detach().numpy().reshape(60,60, 1)\n",
    "    \n",
    "    ig = IntegratedGradients(net_zero)\n",
    "    attr_ig, delta = ig.attribute(inp,\n",
    "                                  target=i,\n",
    "                                  baselines=inp * 0,\n",
    "                                  return_convergence_delta=True)\n",
    "    attr_ig = np.reshape(attr_ig[:, :3600].squeeze().cpu().detach().numpy(), (60,60,1))\n",
    "    \n",
    "    _ = viz.visualize_image_attr(attr_ig, original_image, cmap='bwr', plt_fig_axis=(fig, ax), use_pyplot=False,\n",
    "                                 method=\"blended_heat_map\", sign=\"all\",\n",
    "                                 title='{:.2f}'.format(abs(delta.squeeze().cpu().detach().numpy())) + ', {:1d}'.format(int(rob.squeeze().cpu().detach().numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb979a4",
   "metadata": {},
   "source": [
    "### plot the readout weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6edc5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# get the readout_layer\n",
    "for ni in range(len(cnn.networks)):\n",
    "    if isinstance(cnn.networks[ni], ScaffoldNetwork):\n",
    "        print('readout network index: ', ni)\n",
    "        scaffold_levels = cnn.networks[ni].scaffold_levels\n",
    "    \n",
    "    for li in range(len(cnn.networks[ni].layers)):\n",
    "        try:\n",
    "            num_subs = cnn.networks[ni].layers[li].num_subunits\n",
    "        except:\n",
    "            num_subs = cnn.networks[ni].layers[li].num_filters\n",
    "        num_inh = cnn.networks[ni].layers[li].num_inh\n",
    "        layer_type = cnn.networks[ni].layers[li].layer_dict()['layer_type']\n",
    "        print(ni, li, num_subs, num_inh, layer_type)\n",
    "\n",
    "cnn.networks[0].layers[1].num_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea30b29",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mplt.plot_readout_weights(model=cnn, figsize=(25, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52091e",
   "metadata": {},
   "source": [
    "# inh vs. exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a958050a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from ColorDataUtils import jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5b413",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124e549",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f863ff1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882b7b7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ee133",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(LLsLGN,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba75e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ii in range(3):\n",
    "ii = 0\n",
    "LGNmods[ii].plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGNmods[0].save_model(alt_dirname=dirname2, filename='LGN4lumA.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a9d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = Acnn.get_weights()\n",
    "ks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "k0 = ks[:,:,:,0].reshape([49,11])\n",
    "s = np.zeros([49*11])\n",
    "s.shape, k0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fb434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_iter = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4663d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_iter.networks[0].layers[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f8d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "9*9*11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "glw9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecbf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_lgn_weights = deepcopy(LGNmods[0].networks[0].layers[0].weight.data)\n",
    "good_lgn_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ff848",
   "metadata": {},
   "outputs": [],
   "source": [
    "glw9 = torch.zeros([9,9,11,4])\n",
    "tmp = torch.zeros([7,9,11,4])\n",
    "tmp[:,1:8, :,:] = deepcopy(good_lgn_weights.reshape([7,7,11,4]))\n",
    "glw9[1:8,...] = deepcopy(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99662553",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[:,1:8,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d559b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "glw9.reshape([-1,4]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6162e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGNlags = 11\n",
    "LGNsubs = 4\n",
    "fw0 = 9\n",
    "\n",
    "proj_width = 17\n",
    "\n",
    "Treg = 0.01\n",
    "Xreg = 0.000001\n",
    "Mreg = 0.0001\n",
    "Creg = None\n",
    "Dreg = 0.5\n",
    "Gnet = 0.005\n",
    "\n",
    "num_iter = 4\n",
    "num_subs = 30\n",
    "fwI = 7\n",
    "\n",
    "\n",
    "LGNpars = STconvLayer.layer_dict( \n",
    "    input_dims = data.stim_dims, num_filters=LGNsubs, bias=False, norm_type=1,\n",
    "    filter_dims=[1,fw0,fw0,LGNlags] , NLtype='relu', initialize_center=True)\n",
    "LGNpars['output_norm']='batch'\n",
    "LGNpars['window']='hamming'\n",
    "LGNpars['reg_vals'] = {'d2x':Xreg, 'd2t':Treg, 'center': Creg, 'edge_t':100}  \n",
    "\n",
    "proj_pars = ConvLayer.layer_dict( \n",
    "    num_filters=num_subs, bias=False, norm_type=1, num_inh=num_subs//2,\n",
    "    filter_dims=proj_width, NLtype='lin', initialize_center=True)\n",
    "proj_pars['output_norm']='batch'\n",
    "proj_pars['window']='hamming'\n",
    "\n",
    "Ilayers = IterSTlayer.layer_dict(    \n",
    "    num_filters=num_subs, bias=False, num_iter=num_iter, output_config='full',\n",
    "    pos_constraint=True, res_layer=False, \n",
    "    norm_type=1, num_inh=num_subs//2, filter_width=fwI, num_lags=2, \n",
    "    NLtype='relu', initialize_center=False) \n",
    "Ilayers['output_norm'] = 'batch'\n",
    "# Ilayers['reg_vals'] = {'glocal': Gnet}  \n",
    "        \n",
    "scaffold_net =  FFnetwork.ffnet_dict(\n",
    "    ffnet_type='scaffold', xstim_n = 'stim', layer_list=[LGNpars, proj_pars, Ilayers], scaffold_levels=[1,2] )\n",
    "\n",
    "## 1: READOUT\n",
    "readout_pars = ReadoutLayer.layer_dict(\n",
    "    num_filters=NCv, NLtype='lin', bias=False, pos_constraint=True)\n",
    "readout_pars['gauss_type'] = 'isotropic'\n",
    "readout_pars['reg_vals'] = {'max': Mreg} \n",
    "\n",
    "readout_net = FFnetwork.ffnet_dict( \n",
    "    xstim_n = None, ffnet_n=[0],\n",
    "    layer_list = [readout_pars], ffnet_type='readout')\n",
    "\n",
    "## 2: DRIFT\n",
    "drift_pars = NDNLayer.layer_dict( \n",
    "    input_dims=[1,1,1,NA], num_filters=NCv, bias=False, norm_type=0, NLtype='lin')\n",
    "drift_pars['reg_vals'] = {'d2t': Dreg } \n",
    "\n",
    "drift_net =  FFnetwork.ffnet_dict( xstim_n = 'Xdrift', layer_list = [drift_pars] )\n",
    "\n",
    "## 3: COMB \n",
    "comb_layer = ChannelLayer.layer_dict(\n",
    "    num_filters = NCv, NLtype='softplus', bias=True)\n",
    "comb_layer['weights_initializer'] = 'ones'\n",
    "\n",
    "comb_net = FFnetwork.ffnet_dict( \n",
    "    xstim_n = None, ffnet_n=[1,2],\n",
    "    layer_list = [comb_layer], ffnet_type='add')\n",
    "\n",
    "\n",
    "## LESS ITERATIONS AND LINEAR PROJECTION LAYER (!)\n",
    "\n",
    "LGNmodsNR = []\n",
    "LLsLGN_NR = np.zeros([NCv, 3])\n",
    "for rep in range(3):\n",
    "    cnn_iter = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "    cnn_iter.block_sample = True\n",
    "    \n",
    "    cnn_iter.networks[0].layers[0].weight.data = deepcopy(glw9.reshape([-1, LGNsubs]))\n",
    "    \n",
    "    ## Network 1: readout: fixed mus / sigmas\n",
    "    cnn_iter.networks[1].layers[0].sample = False\n",
    "    #cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "    cnn_iter.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "    cnn_iter.networks[1].set_parameters(val=False, name='mu')\n",
    "    cnn_iter.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "    ## Network 2: drift: not fit\n",
    "    cnn_iter.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "    cnn_iter.networks[2].set_parameters(val=False)\n",
    "\n",
    "    ## Network 3: Comb\n",
    "    cnn_iter.networks[-1].set_parameters(val=False, name='weight')\n",
    "\n",
    "    cnn_iter.fit( data, **adam_parsT, verbose=2, )\n",
    "    LLs = cnn_iter.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "    print(np.mean(LLsNULL-LLs))\n",
    "    LLsLGN_NR[:, rep] = deepcopy(LLsNULL-LLs)\n",
    "    LGNmodsNR.append(deepcopy(cnn_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a13480",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(LLsLGN_NR,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ae4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGNmodsNR[1].plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGNmodsNR[1].save_model(alt_dirname=dirname2, filename='LGN4lumB.pkl')  # this one does not have res-connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b193fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change batch size\n",
    "adam_parsT['batch_size'] =6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking batch-norm off first layer: does it crash the model?\n",
    "LGNlags = 11\n",
    "LGNsubs = 4\n",
    "fw0 = 9\n",
    "\n",
    "proj_width = 17\n",
    "\n",
    "Treg = 0.01\n",
    "Xreg = 0.000001\n",
    "Mreg = 0.0001\n",
    "Creg = None\n",
    "Dreg = 0.5\n",
    "Gnet = 0.005\n",
    "\n",
    "num_iter = 4\n",
    "num_subs = 30\n",
    "fwI = 7\n",
    "\n",
    "LGNpars = STconvLayer.layer_dict( \n",
    "    input_dims = data.stim_dims, num_filters=LGNsubs, bias=False, norm_type=1,\n",
    "    filter_dims=[1,fw0,fw0,LGNlags] , NLtype='relu', initialize_center=True)\n",
    "#LGNpars['output_norm']='batch'\n",
    "LGNpars['window']='hamming'\n",
    "LGNpars['reg_vals'] = {'d2x':Xreg, 'd2t':Treg, 'center': Creg, 'edge_t':100}  \n",
    "\n",
    "proj_pars = ConvLayer.layer_dict( \n",
    "    num_filters=num_subs, bias=False, norm_type=1, num_inh=num_subs//2,\n",
    "    filter_dims=proj_width, NLtype='lin', initialize_center=True)\n",
    "proj_pars['output_norm']='batch'\n",
    "proj_pars['window']='hamming'\n",
    "\n",
    "Ilayers = IterSTlayer.layer_dict(    \n",
    "    num_filters=num_subs, bias=False, num_iter=num_iter, output_config='full',\n",
    "    pos_constraint=True, res_layer=False, \n",
    "    norm_type=1, num_inh=num_subs//2, filter_width=fwI, num_lags=2, \n",
    "    NLtype='relu', initialize_center=False) \n",
    "Ilayers['output_norm'] = 'batch'\n",
    "# Ilayers['reg_vals'] = {'glocal': Gnet}  \n",
    "        \n",
    "scaffold_net =  FFnetwork.ffnet_dict(\n",
    "    ffnet_type='scaffold', xstim_n = 'stim', layer_list=[LGNpars, proj_pars, Ilayers], scaffold_levels=[1,2] )\n",
    "\n",
    "\n",
    "## LESS ITERATIONS AND LINEAR PROJECTION LAYER (!)\n",
    "\n",
    "LGNmods2 = []\n",
    "LLsLGN2 = np.zeros([NCv, 3])\n",
    "for rep in range(3):\n",
    "    cnn_iter = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "    cnn_iter.block_sample = True\n",
    "    \n",
    "    cnn_iter.networks[0].layers[0].weight.data = deepcopy(glw9.reshape([-1, LGNsubs]))\n",
    "    \n",
    "    ## Network 1: readout: fixed mus / sigmas\n",
    "    cnn_iter.networks[1].layers[0].sample = False\n",
    "    #cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "    cnn_iter.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "    cnn_iter.networks[1].set_parameters(val=False, name='mu')\n",
    "    cnn_iter.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "    ## Network 2: drift: not fit\n",
    "    cnn_iter.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "    cnn_iter.networks[2].set_parameters(val=False)\n",
    "\n",
    "    ## Network 3: Comb\n",
    "    cnn_iter.networks[-1].set_parameters(val=False, name='weight')\n",
    "\n",
    "    cnn_iter.fit( data, **adam_parsT, verbose=2, )\n",
    "    LLs = cnn_iter.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "    print(np.mean(LLsNULL-LLs))\n",
    "    LLsLGN2[:, rep] = deepcopy(LLsNULL-LLs)\n",
    "    LGNmods2.append(deepcopy(cnn_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGNmods2[0].plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35012530",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change batch size\n",
    "adam_parsT['accumulated_grad_batches'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1dc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = LGN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73107a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb980d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking batch-norm off first layer: does it crash the model?\n",
    "LGNlags = 11\n",
    "LGNsubs = 4\n",
    "fw0 = 9\n",
    "\n",
    "proj_width = 17\n",
    "\n",
    "Treg = 0.01\n",
    "Xreg = 0.000001\n",
    "Mreg = 0.0001\n",
    "Creg = None\n",
    "Dreg = 0.5\n",
    "Gnet = 0.005\n",
    "\n",
    "num_iter = 5\n",
    "num_subs = 24\n",
    "fwI = 7\n",
    "\n",
    "LGNpars = STconvLayer.layer_dict( \n",
    "    input_dims = data.stim_dims, num_filters=LGNsubs, bias=False, norm_type=1,\n",
    "    filter_dims=[1,fw0,fw0,LGNlags] , NLtype='relu', initialize_center=True)\n",
    "#LGNpars['output_norm']='batch'\n",
    "LGNpars['window']='hamming'\n",
    "LGNpars['reg_vals'] = {'d2x':Xreg, 'd2t':Treg, 'center': Creg, 'edge_t':100}  \n",
    "\n",
    "proj_pars = ConvLayer.layer_dict( \n",
    "    num_filters=num_subs, bias=False, norm_type=1, num_inh=num_subs//2,\n",
    "    filter_dims=proj_width, NLtype='lin', initialize_center=True)\n",
    "proj_pars['output_norm']='batch'\n",
    "proj_pars['window']='hamming'\n",
    "\n",
    "Ilayers = IterSTlayer.layer_dict(    \n",
    "    num_filters=num_subs, bias=False, num_iter=num_iter, output_config='full',\n",
    "    pos_constraint=True, res_layer=False, \n",
    "    norm_type=1, num_inh=num_subs//2, filter_width=fwI, num_lags=2, \n",
    "    NLtype='relu', initialize_center=False) \n",
    "Ilayers['output_norm'] = 'batch'\n",
    "# Ilayers['reg_vals'] = {'glocal': Gnet}  \n",
    "        \n",
    "scaffold_net =  FFnetwork.ffnet_dict(\n",
    "    ffnet_type='scaffold', xstim_n = 'stim', layer_list=[LGNpars, proj_pars, Ilayers], scaffold_levels=[1,2] )\n",
    "\n",
    "\n",
    "## LESS ITERATIONS AND LINEAR PROJECTION LAYER (!)\n",
    "\n",
    "LGNmods5 = []\n",
    "LLsLGN5 = np.zeros([NCv, 3])\n",
    "for rep in range(3):\n",
    "    cnn_iter = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "    cnn_iter.block_sample = True\n",
    "    \n",
    "    cnn_iter.networks[0].layers[0].weight.data = deepcopy(glw9.reshape([-1, LGNsubs]))\n",
    "    \n",
    "    ## Network 1: readout: fixed mus / sigmas\n",
    "    cnn_iter.networks[1].layers[0].sample = False\n",
    "    #cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "    cnn_iter.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "    cnn_iter.networks[1].set_parameters(val=False, name='mu')\n",
    "    cnn_iter.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "    ## Network 2: drift: not fit\n",
    "    cnn_iter.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "    cnn_iter.networks[2].set_parameters(val=False)\n",
    "\n",
    "    ## Network 3: Comb\n",
    "    cnn_iter.networks[-1].set_parameters(val=False, name='weight')\n",
    "\n",
    "    cnn_iter.fit( data, **adam_parsT, verbose=2, )\n",
    "    LLs = cnn_iter.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "    print(np.mean(LLsNULL-LLs))\n",
    "    LLsLGN5[:, rep] = deepcopy(LLsNULL-LLs)\n",
    "    LGNmods5.append(deepcopy(cnn_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe2ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f502639",
   "metadata": {},
   "source": [
    "### Network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b097e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Acnn = deepcopy(LGNmods[0])\n",
    "LLs = Acnn.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "isus = np.intersect1d(data.SUs, valET)\n",
    "print(len(isus), 'cells')\n",
    "print(np.mean(LLsNULL-LLs), np.mean(LLsNULL[isus]-LLs[isus]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e559cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ilayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7aa1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ann.plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c3c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "wR = Acnn.get_weights(ffnet_target=1)\n",
    "quick_readout_display(wR[:, isus], 0, 30, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf2c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCsu = len(isus)\n",
    "NF = wR.shape[0]\n",
    "lvlws = np.zeros([10, NCsu])\n",
    "for ii in range(10):\n",
    "    lvlws[ii, :] = (-1)**ii*np.sum(wR[np.arange(15)+ii*15, :][:,isus],axis=0)\n",
    "ss(rh=10)\n",
    "imagesc(lvlws.T, cmap='bwr', balanced=True)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea13b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = 8\n",
    "plt.plot(lvlws[:,cc])\n",
    "plt.plot([0,9],[0,0],'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PICK SUBUNIT OUTPUT FOR stim\n",
    "rlags = 16\n",
    "C = 1.0\n",
    "xrange = np.arange(15,45)\n",
    "T = rlags*len(xrange)**2\n",
    "mapstim = torch.zeros([T, NX, NX], dtype=torch.float32)\n",
    "tt = 0\n",
    "for xx in xrange:\n",
    "    for yy in xrange:\n",
    "        mapstim[rlags*tt, xx, yy] = C\n",
    "        tt += 1\n",
    "mapstim = mapstim.reshape([T, -1])\n",
    "mapstim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9111aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map LGNlayer --  Samples from middle response, spaial map as function of lag for each filter\n",
    "g0on = Acnn.networks[0].layers[0](mapstim)\n",
    "g0off = Acnn.networks[0].layers[0](-mapstim)\n",
    "g0on.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f54bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1on = Acnn.networks[0].layers[1](g0on)\n",
    "g1off = Acnn.networks[0].layers[1](g0off)\n",
    "g1on.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea28a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2on = Acnn.networks[0].layers[2](g1on)\n",
    "g2off = Acnn.networks[0].layers[2](g1off)\n",
    "g2on.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3216a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NXc = len(xrange)\n",
    "lvl0on = g0on.reshape([NXc,NXc, rlags, -1, NX, NX])[...,29,29].detach().numpy()\n",
    "lvl0off = g0off.reshape([NXc,NXc, rlags, -1, NX, NX])[...,29,29].detach().numpy()\n",
    "lvl0 = lvl0on-lvl0off\n",
    "lvl0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl1on = g1on.reshape([NXc,NXc, rlags, -1, NX, NX])[...,29,29].detach().numpy()\n",
    "lvl1off = g1off.reshape([NXc,NXc, rlags, -1, NX, NX])[...,29,29].detach().numpy()\n",
    "lvl1 = lvl1on-lvl1off\n",
    "lvl1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c1aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl2on = g2on.reshape([NXc,NXc, rlags, -1, NX, NX])[...,29,29].detach().numpy()\n",
    "lvl2off = g2off.reshape([NXc,NXc, rlags, -1, NX, NX])[...,29,29].detach().numpy()\n",
    "lvl2 = lvl2on-lvl2off\n",
    "lvl2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5813c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfunc = np.std(lvl0.reshape([-1,rlags,4]), axis=0)\n",
    "tfuncON = np.std(lvl0on.reshape([-1,rlags,4]), axis=0)\n",
    "tfuncOFF = np.std(lvl0off.reshape([-1,rlags,4]), axis=0)\n",
    "plt.plot(tfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4960a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LGN layer selectivity\n",
    "tfunc = np.std(lvl0.reshape([-1,rlags,4]), axis=0)\n",
    "tfuncON = np.std(lvl0on.reshape([-1,rlags,4]), axis=0)\n",
    "tfuncOFF = np.std(lvl0off.reshape([-1,rlags,4]), axis=0)\n",
    "\n",
    "for cc in range(4):\n",
    "    # Temporal response function \n",
    "    print('LGN filter', cc)\n",
    "    blag = np.argmax(tfunc[:,cc])\n",
    "    ss(1,4)\n",
    "    plt.subplot(141)\n",
    "    imagesc(lvl0[:,:,np.argmax(tfunc[:,cc]), cc], balanced=True)\n",
    "    plt.subplot(142)\n",
    "    imagesc(lvl0on[:,:,np.argmax(tfuncON[:,cc]), cc], balanced=True)\n",
    "    plt.subplot(143)\n",
    "    imagesc(-lvl0off[:,:,np.argmax(tfuncOFF[:,cc]), cc], balanced=True)\n",
    "    plt.subplot(144)\n",
    "    plt.plot(tfunc[:,cc],'k')\n",
    "    plt.plot(tfuncON[:,cc],'r')\n",
    "    plt.plot(-tfuncOFF[:,cc],'b')\n",
    "    plt.plot([0,rlags-1],[0,0],'k--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203dffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NF = lvl1on.shape[-1]\n",
    "tfunc2 = np.std(lvl1.reshape([-1,rlags,NF]), axis=0)\n",
    "tfunc2ON = np.std(lvl1on.reshape([-1,rlags,NF]), axis=0)\n",
    "tfunc2OFF = np.std(lvl1off.reshape([-1,rlags,NF]), axis=0)\n",
    "plt.plot(tfuncON)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9631a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa39c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss(10,9, rh=1.6)\n",
    "for cc in range(NF):\n",
    "    # Temporal response function \n",
    "    m = np.median(lvl1on[...,cc])\n",
    "    plt.subplot(10,9,3*cc+1)\n",
    "    imagesc(lvl1on[:,:,np.argmax(tfuncON[:,cc]), cc]-m, balanced=True)\n",
    "    plt.title(\"f%d ON\"%cc)\n",
    "    plt.subplot(10,9,3*cc+2)\n",
    "    imagesc(lvl1off[:,:,np.argmax(tfuncOFF[:,cc]), cc]-m, balanced=True)\n",
    "    plt.title(\"f%d OFF\"%cc)\n",
    "    plt.subplot(10,9,3*cc+3)\n",
    "    plt.plot(tfuncON[:,cc],'r')\n",
    "    plt.plot(-tfuncOFF[:,cc],'b')\n",
    "    plt.plot([0,rlags-1],[0,0],'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "NF = lvl2on.shape[-1]\n",
    "tfunc2 = np.std(lvl2.reshape([-1,rlags,NF]), axis=0)\n",
    "tfunc2ON = np.std(lvl2on.reshape([-1,rlags,NF]), axis=0)\n",
    "tfunc2OFF = np.std(lvl2off.reshape([-1,rlags,NF]), axis=0)\n",
    "plt.plot(tfunc2ON)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964aaccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl2on.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ddf7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ll in range(4):\n",
    "    print(\"Iter level %d\"%ll)\n",
    "    ss(10,9, rh=1.6)\n",
    "    for cc in range(30):\n",
    "        if cc < 15:\n",
    "            tp = 'EXC'\n",
    "        else:\n",
    "            tp = 'INH'\n",
    "        ff = cc+ll*30\n",
    "        # Temporal response function \n",
    "        m = np.median(lvl2on[...,ff])\n",
    "        plt.subplot(10,9,3*cc+1)\n",
    "        blag0 = np.argmax(tfunc2ON[2:,ff])+2\n",
    "        imagesc(lvl2on[:,:,blag0, ff]-m, balanced=True)\n",
    "        plt.title(\"f%d ON (L%d)\"%(ff, blag0))\n",
    "        plt.subplot(10,9,3*cc+2)\n",
    "        blag1 = np.argmax(tfunc2OFF[2:,ff])+2\n",
    "        imagesc(lvl2off[:,:,blag1, ff]-m, balanced=True)\n",
    "        plt.title(\"f%d OFF (L%d)\"%(ff, blag1))\n",
    "        plt.subplot(10,9,3*cc+3)\n",
    "        plt.plot(tfunc2ON[:,ff],'r')\n",
    "        plt.plot(-tfunc2OFF[:,ff],'b')\n",
    "        plt.plot([0,rlags-1],[0,0],'k--')\n",
    "        plt.title(tp)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd38a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK ALL EXCITATION AND INHIBITION\n",
    "plt.plot(tfunc2ON[:, ll*30+ii*5+np.arange(5)]/np.mean(tfunc2ON[:, ll*30+ii*5+np.arange(5)],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144b4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.median(lvl2on[...,ff])\n",
    "imagesc(lvl2on[:,:,1, ff]-m)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf29222",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 0\n",
    "np.mean(tfunc2ON[1:, ll*30+ii*5+np.arange(5)],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss(4,3, rh=4)\n",
    "mt = np.mean(np.concatenate((tfunc2ON,tfunc2ON),axis=1),axis=1)\n",
    "for ll in range(4):\n",
    "    mEon = np.mean(tfunc2ON[:, ll*30+np.arange(15)],axis=1)\n",
    "    mIon = np.mean(tfunc2ON[:, ll*30+np.arange(15,30)],axis=1)\n",
    "    mEof = np.mean(tfunc2OFF[:, ll*30+np.arange(15)],axis=1)\n",
    "    mIof = np.mean(tfunc2OFF[:, ll*30+np.arange(15,30)],axis=1)\n",
    "    plt.subplot(4,3,ll*3+1)\n",
    "    plt.plot([0,15],[0,0],'k')\n",
    "    plt.plot(mEon/np.mean(mEon[1:]),'r')\n",
    "    plt.plot(-mEof/np.mean(mEof[1:]),'r--')\n",
    "    plt.plot(mIon/np.mean(mIon[1:]),'b')\n",
    "    plt.plot(-mIof/np.mean(mIof[1:]),'b--')\n",
    "    plt.plot(mt/np.mean(mt[1:]),'k--')\n",
    "    plt.plot(-mt/np.mean(mt[1:]),'k--')\n",
    "\n",
    "    plt.subplot(4,3,ll*3+2)\n",
    "    plt.plot([0,15],[0,0],'k')\n",
    "    plt.plot(tfunc2ON[:, ll*30+np.arange(15)]/np.mean(tfunc2ON[1:, ll*30+np.arange(15)],axis=0),'r')\n",
    "    plt.plot(-tfunc2OFF[:, ll*30+np.arange(15)]/np.mean(tfunc2OFF[1:, ll*30+np.arange(15)],axis=0),'r--')\n",
    "    plt.plot(mt/np.mean(mt[1:]),'k--')\n",
    "    plt.plot(-mt/np.mean(mt[1:]),'k--')\n",
    "\n",
    "    plt.subplot(4,3,ll*3+3)\n",
    "    plt.plot([0,15],[0,0],'k')\n",
    "    plt.plot(tfunc2ON[:, ll*30+np.arange(15,30)]/np.mean(tfunc2ON[1:, ll*30+np.arange(15,30)],axis=0),'b')\n",
    "    plt.plot(-tfunc2OFF[:, ll*30+np.arange(15,30)]/np.mean(tfunc2OFF[1:, ll*30+np.arange(15,30)],axis=0),'b')\n",
    "    plt.plot(mt/np.mean(mt[1:]),'k--')\n",
    "    plt.plot(-mt/np.mean(mt[1:]),'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5263f252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cc = 0\n",
    "imagesc(-lvl0off[:,:,3, cc], balanced=True)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ba6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for projection layer\n",
    "R1on = Acnn.networks[0].layers[1](R0on.reshape([NX*NX*rlags,-1])).reshape([NX,NX, rlags, -1, NX, NX])\n",
    "R1off = Acnn.networks[0].layers[1](R0off.reshape([NX*NX*rlags,-1])).reshape([NX,NX, rlags, -1, NX, NX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1on = R1on[...,29,29].detach().numpy()\n",
    "L1off = R1off[...,29,29].detach().numpy()\n",
    "R1 = L1on-L1off\n",
    "R1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c3cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for projection layer\n",
    "IterON = Acnn.networks[0].layers[2](R1on.reshape([NX*NX*rlags,-1])).reshape([NX,NX, rlags, -1, NX, NX])\n",
    "IterOFF = Acnn.networks[0].layers[2](R1off.reshape([NX*NX*rlags,-1])).reshape([NX,NX, rlags, -1, NX, NX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f1edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LGN layer selectivity\n",
    "for cc in range(4):\n",
    "    # Temporal response function \n",
    "    print('LGN filter', cc)\n",
    "    tfunc = np.std(R0.reshape([-1,20,4]), axis=0)[:,cc]\n",
    "    tfuncON = np.std(R0on.reshape([-1,20,4]), axis=0)[:,cc]\n",
    "    tfuncOFF = np.std(R0off.reshape([-1,20,4]), axis=0)[:,cc]\n",
    "    blag = np.argmax(tfunc)\n",
    "    ss(1,4)\n",
    "    plt.subplot(141)\n",
    "    imagesc(R0[:,:,blag, cc], balanced=True)\n",
    "    plt.subplot(142)\n",
    "    imagesc(R0on[:,:,blag, cc], balanced=True)\n",
    "    plt.subplot(143)\n",
    "    imagesc(-R0off[:,:,blag, cc], balanced=True)\n",
    "    plt.subplot(144)\n",
    "    plt.plot(tfunc,'k')\n",
    "    plt.plot(tfuncON,'r')\n",
    "    plt.plot(tfuncOFF,'b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98ad49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f904206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f642da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15321d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss()\n",
    "plt.plot(R0[29*60+29, :, 0, 29,29].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa454a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff59eade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1205b1b6",
   "metadata": {},
   "source": [
    "## MORE MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0edbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COPY OF OTHER MODEL (on other notebook with different fit seed)\n",
    "LGNlags = 11\n",
    "LGNsubs = 8\n",
    "fw0 = 7\n",
    "\n",
    "proj_width = 17\n",
    "\n",
    "Treg = 0.01\n",
    "Xreg = 0.00001\n",
    "Mreg = 0.0001\n",
    "Creg = 0.001\n",
    "Dreg = 0.5\n",
    "Gnet = 0.005\n",
    "\n",
    "num_iter = 5\n",
    "num_subs = 30\n",
    "fwI = 7\n",
    "\n",
    "LGNpars = STconvLayer.layer_dict( \n",
    "    input_dims = data.stim_dims, num_filters=LGNsubs, bias=False, norm_type=1, num_inh=4,\n",
    "    filter_dims=[1,fw0,fw0,LGNlags] , NLtype='relu', initialize_center=True)\n",
    "LGNpars['output_norm']='batch'\n",
    "LGNpars['window']='hamming'\n",
    "LGNpars['reg_vals'] = {'d2x':Xreg, 'd2t':Treg, 'center': Creg, 'edge_t':100}  \n",
    "\n",
    "proj_pars = ConvLayer.layer_dict( \n",
    "    num_filters=num_subs, bias=False, norm_type=1, num_inh=num_subs//2, positive_constraints=True,\n",
    "    filter_dims=proj_width, NLtype='relu', initialize_center=True)\n",
    "proj_pars['output_norm']='batch'\n",
    "proj_pars['window']='hamming'\n",
    "\n",
    "Ilayers = IterSTlayer.layer_dict(    \n",
    "    num_filters=num_subs, bias=False, num_iter=num_iter, output_config='full',\n",
    "    pos_constraint=True,\n",
    "    norm_type=1, num_inh=num_subs//2, filter_width=fwI, num_lags=2, \n",
    "    NLtype='relu', initialize_center=False) \n",
    "Ilayers['output_norm'] = 'batch'\n",
    "Ilayers['reg_vals'] = {'center': Creg}  \n",
    "# Ilayers['reg_vals'] = {'glocal': Gnet}  \n",
    "        \n",
    "scaffold_net =  FFnetwork.ffnet_dict(\n",
    "    ffnet_type='scaffold', xstim_n = 'stim', layer_list=[LGNpars, proj_pars, Ilayers], scaffold_levels=[1,2] )\n",
    "\n",
    "cnnEI = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "cnnEI.block_sample = True\n",
    "\n",
    "## Network 1: readout: fixed mus / sigmas\n",
    "cnnEI.networks[1].layers[0].sample = False\n",
    "#cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "cnnEI.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "cnnEI.networks[1].set_parameters(val=False, name='mu')\n",
    "cnnEI.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "## Network 2: drift: not fit\n",
    "cnnEI.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "cnnEI.networks[2].set_parameters(val=False)\n",
    "\n",
    "## Network 3: Comb\n",
    "cnnEI.networks[-1].set_parameters(val=False, name='weight')\n",
    "\n",
    "cnnEI.fit( data, **adam_parsT, verbose=2, seed=14)\n",
    "LLs = cnnEI.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "print(np.mean(LLsNULL-LLs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc96be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnEI.plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e43ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnEIsave1 = deepcopy(cnnEI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "## COPY OF OTHER MODEL (on other notebook with different fit seed)\n",
    "LGNlags = 11\n",
    "LGNsubs = 8\n",
    "fw0 = 7\n",
    "\n",
    "proj_width = 17\n",
    "\n",
    "Treg = 0.01\n",
    "Xreg = 0.00001\n",
    "Mreg = 0.0001\n",
    "Creg = 0.001\n",
    "Dreg = 0.5\n",
    "Gnet = 0.005\n",
    "\n",
    "num_iter = 5\n",
    "num_subs = 30\n",
    "fwI = 7\n",
    "\n",
    "LGNpars = STconvLayer.layer_dict( \n",
    "    input_dims = data.stim_dims, num_filters=LGNsubs, bias=False, norm_type=1, num_inh=4,\n",
    "    filter_dims=[1,fw0,fw0,LGNlags] , NLtype='relu', initialize_center=True)\n",
    "LGNpars['output_norm']='batch'\n",
    "LGNpars['window']='hamming'\n",
    "LGNpars['reg_vals'] = {'d2x':Xreg, 'd2t':Treg, 'center': Creg, 'edge_t':100}  \n",
    "\n",
    "proj_pars = ConvLayer.layer_dict( \n",
    "    num_filters=num_subs, bias=False, norm_type=1, num_inh=num_subs//2, positive_constraints=True,\n",
    "    filter_dims=proj_width, NLtype='relu', initialize_center=True)\n",
    "proj_pars['output_norm']='batch'\n",
    "proj_pars['window']='hamming'\n",
    "\n",
    "Ilayers = IterSTlayer.layer_dict(    \n",
    "    num_filters=num_subs, bias=False, num_iter=num_iter, output_config='full',\n",
    "    pos_constraint=True,\n",
    "    norm_type=1, num_inh=num_subs//2, filter_width=fwI, num_lags=2, \n",
    "    NLtype='relu', initialize_center=False) \n",
    "Ilayers['output_norm'] = 'batch'\n",
    "Ilayers['reg_vals'] = {'center': Creg}  \n",
    "# Ilayers['reg_vals'] = {'glocal': Gnet}  \n",
    "        \n",
    "scaffold_net =  FFnetwork.ffnet_dict(\n",
    "    ffnet_type='scaffold', xstim_n = 'stim', layer_list=[LGNpars, proj_pars, Ilayers], scaffold_levels=[1,2] )\n",
    "\n",
    "cnnEI = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "cnnEI.block_sample = True\n",
    "\n",
    "## Network 1: readout: fixed mus / sigmas\n",
    "cnnEI.networks[1].layers[0].sample = False\n",
    "#cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "cnnEI.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "cnnEI.networks[1].set_parameters(val=False, name='mu')\n",
    "cnnEI.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "## Network 2: drift: not fit\n",
    "cnnEI.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "cnnEI.networks[2].set_parameters(val=False)\n",
    "\n",
    "## Network 3: Comb\n",
    "cnnEI.networks[-1].set_parameters(val=False, name='weight')\n",
    "\n",
    "cnnEI.fit( data, **adam_parsT, verbose=2, seed=14)\n",
    "LLs = cnnEI.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "print(np.mean(LLsNULL-LLs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713ed37",
   "metadata": {},
   "source": [
    "## Previously run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c137e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGNlags = 10\n",
    "LGNsubs = 4\n",
    "fw0 = 7\n",
    "\n",
    "proj_width = 15\n",
    "\n",
    "#num_lags=14\n",
    "## Try Hamming window -- increase by 2 on a side?\n",
    "Treg = 0.01\n",
    "Xreg = 0.00001\n",
    "Mreg = 0.0001\n",
    "Creg = None\n",
    "Dreg = 0.5\n",
    "Gnet = 0.005\n",
    "\n",
    "num_iter = 4\n",
    "num_subs = 30\n",
    "fwI = 5\n",
    "\n",
    "LGNpars = STconvLayer.layer_dict( \n",
    "    input_dims = data.stim_dims, num_filters=LGNsubs, bias=False, norm_type=1,\n",
    "    filter_dims=[1,fw0,fw0,LGNlags] , NLtype='relu', initialize_center=True)\n",
    "LGNpars['output_norm']='batch'\n",
    "LGNpars['window']='hamming'\n",
    "LGNpars['reg_vals'] = {'d2x':Xreg, 'd2t':Treg, 'center': Creg, 'edge_t':100}  \n",
    "\n",
    "proj_pars = ConvLayer.layer_dict( \n",
    "    num_filters=num_subs, bias=False, norm_type=1, num_inh=num_subs//2,\n",
    "    filter_dims=proj_width, NLtype='lin', initialize_center=True)\n",
    "proj_pars['output_norm']='batch'\n",
    "proj_pars['window']='hamming'\n",
    "\n",
    "Ilayers = IterSTlayer.layer_dict(    \n",
    "    num_filters=num_subs, bias=False, num_iter=num_iter, output_config='full',\n",
    "    pos_constraint=True, \n",
    "    norm_type=1, num_inh=num_subs//2, filter_width=fwI, num_lags=3, \n",
    "    NLtype='relu', initialize_center=False) \n",
    "Ilayers['output_norm'] = 'batch'\n",
    "# Ilayers['reg_vals'] = {'glocal': Gnet}  \n",
    "        \n",
    "scaffold_net =  FFnetwork.ffnet_dict(\n",
    "    ffnet_type='scaffold', xstim_n = 'stim', layer_list=[LGNpars, proj_pars, Ilayers], scaffold_levels=[1,2] )\n",
    "\n",
    "## 1: READOUT\n",
    "readout_pars = ReadoutLayer.layer_dict(\n",
    "    num_filters=NCv, NLtype='lin', bias=False, pos_constraint=True)\n",
    "readout_pars['gauss_type'] = 'isotropic'\n",
    "readout_pars['reg_vals'] = {'max': Mreg} \n",
    "\n",
    "readout_net = FFnetwork.ffnet_dict( \n",
    "    xstim_n = None, ffnet_n=[0],\n",
    "    layer_list = [readout_pars], ffnet_type='readout')\n",
    "\n",
    "## 2: DRIFT\n",
    "drift_pars = NDNLayer.layer_dict( \n",
    "    input_dims=[1,1,1,NA], num_filters=NCv, bias=False, norm_type=0, NLtype='lin')\n",
    "drift_pars['reg_vals'] = {'d2t': Dreg } \n",
    "\n",
    "drift_net =  FFnetwork.ffnet_dict( xstim_n = 'Xdrift', layer_list = [drift_pars] )\n",
    "\n",
    "## 3: COMB \n",
    "comb_layer = ChannelLayer.layer_dict(\n",
    "    num_filters = NCv, NLtype='softplus', bias=True)\n",
    "comb_layer['weights_initializer'] = 'ones'\n",
    "\n",
    "comb_net = FFnetwork.ffnet_dict( \n",
    "    xstim_n = None, ffnet_n=[1,2],\n",
    "    layer_list = [comb_layer], ffnet_type='add')\n",
    "\n",
    "cnn_iter = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "cnn_iter.block_sample = True\n",
    "\n",
    "## Network 1: readout: fixed mus / sigmas\n",
    "cnn_iter.networks[1].layers[0].sample = False\n",
    "#cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "cnn_iter.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "cnn_iter.networks[1].set_parameters(val=False, name='mu')\n",
    "cnn_iter.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "## Network 2: drift: not fit\n",
    "cnn_iter.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "cnn_iter.networks[2].set_parameters(val=False)\n",
    "\n",
    "## Network 3: Comb\n",
    "cnn_iter.networks[-1].set_parameters(val=False, name='weight')\n",
    "cnn_iter.fit( data, **adam_parsT, verbose=2, )\n",
    "LLs = cnn_iter.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "print(np.mean(LLsNULL-LLs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c765793",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_iter.plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86687c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUM4cnn1 = deepcopy(cnn_iter)\n",
    "LUM4cnn1.save_model(alt_dirname=dirname2, filename='LGN4lum.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ffb1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = cnn_iter.get_weights(ffnet_target=0, layer_target=1)\n",
    "C, L, L, N = w.shape\n",
    "ss(N,C)\n",
    "for nn in range(N):\n",
    "    m = np.max(abs(w[..., nn]))\n",
    "    for cc in range(C):\n",
    "        plt.subplot(N,C, nn*C+1+cc)\n",
    "        imagesc(w[cc,:,:,nn], max=m)\n",
    "        if cc == 0:\n",
    "            plt.ylabel(str(nn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66006f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4852d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b56be04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take out resnet out and re-fit: how much hurt?\n",
    "\n",
    "Ilayers = IterSTlayer.layer_dict(    \n",
    "    num_filters=num_subs, bias=False, num_iter=num_iter, output_config='full',\n",
    "    pos_constraint=True, \n",
    "    norm_type=1, num_inh=num_subs//2, filter_width=fwI, num_lags=3, res_layer=False,  # only change\n",
    "    NLtype='relu', initialize_center=False) \n",
    "Ilayers['output_norm'] = 'batch'\n",
    "# Ilayers['reg_vals'] = {'glocal': Gnet}  \n",
    "        \n",
    "scaffold_net =  FFnetwork.ffnet_dict(\n",
    "    ffnet_type='scaffold', xstim_n = 'stim', layer_list=[LGNpars, proj_pars, Ilayers], scaffold_levels=[1,2] )\n",
    "\n",
    "cnn4a = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "cnn4a.block_sample = True\n",
    "\n",
    "## Network 1: readout: fixed mus / sigmas\n",
    "cnn4a.networks[1].layers[0].sample = False\n",
    "#cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "cnn4a.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "cnn4a.networks[1].set_parameters(val=False, name='mu')\n",
    "cnn4a.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "## Network 2: drift: not fit\n",
    "cnn4a.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "cnn4a.networks[2].set_parameters(val=False)\n",
    "\n",
    "## Network 3: Comb\n",
    "cnn4a.networks[-1].set_parameters(val=False, name='weight')\n",
    "cnn4a.fit( data, **adam_parsT, verbose=2, )\n",
    "LLs = cnn4a.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "print(np.mean(LLsNULL-LLs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4a.plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4a.save_model(alt_dirname=dirname2, filename='LGN4lumNR1.pkl')  # no res layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cddd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sublist = [2, 4, 6]\n",
    "n_iter = 3\n",
    "LUMmods = []\n",
    "LLsLUM = np.zeros([len(sublist), n_iter])\n",
    "for nsubs in range(len(sublist)):\n",
    "    scaffold_net['layer_list'][0]['num_filters'] = sublist[nsubs]\n",
    "    for ii in range(n_iter):\n",
    "        cnn_iter = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "        cnn_iter.block_sample = True\n",
    "\n",
    "        ## Network 1: readout: fixed mus / sigmas\n",
    "        cnn_iter.networks[1].layers[0].sample = False\n",
    "        #cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "        cnn_iter.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "        cnn_iter.networks[1].set_parameters(val=False, name='mu')\n",
    "        cnn_iter.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "        ## Network 2: drift: not fit\n",
    "        cnn_iter.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "        cnn_iter.networks[2].set_parameters(val=False)\n",
    "\n",
    "        ## Network 3: Comb\n",
    "        cnn_iter.networks[-1].set_parameters(val=False, name='weight')\n",
    "        cnn_iter.fit( data, **adam_parsT, verbose=2, seed=ii )\n",
    "        LLs = cnn_iter.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "        print(\"%2d subs, iter %d: %0.8f\\n\"%(sublist[nsubs], ii, np.mean(LLsNULL-LLs)))\n",
    "        LLsLUM[nsubs, ii] = np.mean(LLsNULL-LLs)\n",
    "        print(LLsLUM)\n",
    "        LUMmods.append(deepcopy(cnn_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78519daf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "LUMmods[1].plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUMmods[4].plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fd0003",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = LUMmods[4].get_weights(ffnet_target=0, layer_target=1)\n",
    "C, L, L, N = w.shape\n",
    "ss(N,C)\n",
    "for nn in range(N):\n",
    "    m = np.max(abs(w[..., nn]))\n",
    "    for cc in range(C):\n",
    "        plt.subplot(N,C, nn*C+1+cc)\n",
    "        imagesc(w[cc,:,:,nn], max=m)\n",
    "        if cc == 0:\n",
    "            plt.ylabel(str(nn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7109e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUMmods[-1].plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUMmods[4].save_model(alt_dirname=dirname2, filename='LGN4lumNR2.pkl')  # no res layer\n",
    "LUMmods[3].save_model(alt_dirname=dirname2, filename='LGN4lumNR3.pkl')  # no res layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd204c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85114540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGED NUMBER OF LAGS ONLY\n",
    "Ilayers = IterSTlayer.layer_dict(    \n",
    "    num_filters=num_subs, bias=False, num_iter=num_iter, output_config='full',\n",
    "    pos_constraint=True, \n",
    "    norm_type=1, num_inh=num_subs//2, filter_width=fwI, num_lags=2, res_layer=False,  # only change\n",
    "    NLtype='relu', initialize_center=False) \n",
    "Ilayers['output_norm'] = 'batch'\n",
    "# Ilayers['reg_vals'] = {'glocal': Gnet}  \n",
    "\n",
    "scaffold_net =  FFnetwork.ffnet_dict(\n",
    "    ffnet_type='scaffold', xstim_n = 'stim', layer_list=[LGNpars, proj_pars, Ilayers], scaffold_levels=[1,2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe116a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sublist = [4, 5]\n",
    "n_iter = 3\n",
    "LUMmods2 = []\n",
    "LLsLUM2 = np.zeros([len(sublist), n_iter])\n",
    "for nsubs in range(len(sublist)):\n",
    "    scaffold_net['layer_list'][0]['num_filters'] = sublist[nsubs]\n",
    "    for ii in range(n_iter):\n",
    "        cnn_iter = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "        cnn_iter.block_sample = True\n",
    "\n",
    "        ## Network 1: readout: fixed mus / sigmas\n",
    "        cnn_iter.networks[1].layers[0].sample = False\n",
    "        #cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "        cnn_iter.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "        cnn_iter.networks[1].set_parameters(val=False, name='mu')\n",
    "        cnn_iter.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "        ## Network 2: drift: not fit\n",
    "        cnn_iter.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "        cnn_iter.networks[2].set_parameters(val=False)\n",
    "\n",
    "        ## Network 3: Comb\n",
    "        cnn_iter.networks[-1].set_parameters(val=False, name='weight')\n",
    "        cnn_iter.fit( data, **adam_parsT, verbose=2, seed=ii )\n",
    "        LLs = cnn_iter.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "        print(\"%2d subs, iter %d: %0.8f\\n\"%(sublist[nsubs], ii, np.mean(LLsNULL-LLs)))\n",
    "        LLsLUM2[nsubs, ii] = np.mean(LLsNULL-LLs)\n",
    "        print(LLsLUM2)\n",
    "        LUMmods2.append(deepcopy(cnn_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ace8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUMmods2[2].save_model(alt_dirname=dirname2, filename='LGN4lumNRL1.pkl')  # no res layer - short latency\n",
    "LUMmods2[3].save_model(alt_dirname=dirname2, filename='LGN5lumNRL1.pkl')  # no res layer - short latency 5\n",
    "LUMmods2[5].save_model(alt_dirname=dirname2, filename='LGN5lumNRL2.pkl')  # no res layer - short latency 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7570b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUMmods2[2].plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5da4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wR = LUMmods2[2].get_weights(ffnet_target=1)\n",
    "wR.shape\n",
    "quick_readout_display(LUMmods2[2].get_weights(ffnet_target=1), 4, 30, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68147b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "wR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8827698",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGNlags = 10\n",
    "LGNsubs = 4\n",
    "fw0 = 9\n",
    "\n",
    "proj_width = 17\n",
    "\n",
    "Treg = 0.01\n",
    "Xreg = 0.00001\n",
    "Mreg = 0.0001\n",
    "Creg = None\n",
    "Dreg = 0.5\n",
    "Gnet = 0.005\n",
    "\n",
    "num_iter = 4\n",
    "num_subs = 30\n",
    "fwI = 5\n",
    "\n",
    "LGNpars = STconvLayer.layer_dict( \n",
    "    input_dims = data.stim_dims, num_filters=LGNsubs, bias=False, norm_type=1,\n",
    "    filter_dims=[1,fw0,fw0,LGNlags] , NLtype='relu', initialize_center=True)\n",
    "LGNpars['output_norm']='batch'\n",
    "LGNpars['window']='hamming'\n",
    "LGNpars['reg_vals'] = {'d2x':Xreg, 'd2t':Treg, 'center': Creg, 'edge_t':100}  \n",
    "\n",
    "proj_pars = ConvLayer.layer_dict( \n",
    "    num_filters=num_subs, bias=False, norm_type=1, num_inh=num_subs//2,\n",
    "    filter_dims=proj_width, NLtype='relu', initialize_center=True)\n",
    "proj_pars['output_norm']='batch'\n",
    "proj_pars['window']='hamming'\n",
    "\n",
    "Ilayers = IterSTlayer.layer_dict(    \n",
    "    num_filters=num_subs, bias=False, num_iter=num_iter, output_config='full',\n",
    "    pos_constraint=True,\n",
    "    norm_type=1, num_inh=num_subs//2, filter_width=fwI, num_lags=2, \n",
    "    NLtype='relu', initialize_center=False) \n",
    "Ilayers['output_norm'] = 'batch'\n",
    "# Ilayers['reg_vals'] = {'glocal': Gnet}  \n",
    "        \n",
    "scaffold_net =  FFnetwork.ffnet_dict(\n",
    "    ffnet_type='scaffold', xstim_n = 'stim', layer_list=[LGNpars, proj_pars, Ilayers], scaffold_levels=[1,2] )\n",
    "\n",
    "cnn_iter = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "cnn_iter.block_sample = True\n",
    "\n",
    "## Network 1: readout: fixed mus / sigmas\n",
    "cnn_iter.networks[1].layers[0].sample = False\n",
    "#cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "cnn_iter.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "cnn_iter.networks[1].set_parameters(val=False, name='mu')\n",
    "cnn_iter.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "## Network 2: drift: not fit\n",
    "cnn_iter.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "cnn_iter.networks[2].set_parameters(val=False)\n",
    "\n",
    "## Network 3: Comb\n",
    "cnn_iter.networks[-1].set_parameters(val=False, name='weight')\n",
    "cnn_iter.fit( data, **adam_parsT, verbose=2, seed=ii )\n",
    "LLs = cnn_iter.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "print(np.mean(LLsNULL-LLs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a1266",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGN4mods[0].plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f41e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGN4mods[2].plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e366ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_readout_display(LGN4mods[2].get_weights(ffnet_target=1), 0, 30, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2194d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGN4mods[2].get_weights(ffnet_target=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27357e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = LUMmods2[2].get_weights(ffnet_target=1)\n",
    "ss(rh=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88086565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_readout_display(w, start_n, num_subs, inh_frac):\n",
    "    NF, NC = w.shape\n",
    "    num_layers = (NF-start_n)//num_subs\n",
    "    assert num_layers == (NF-start_n)/num_subs, \"something wrong %f\"%(NF-start_n)/num_subs\n",
    "    NE = num_subs-num_subs//inh_frac\n",
    "    for ii in range(num_layers):\n",
    "        w[start_n+num_subs*ii+np.arange(NE, num_subs), :] *= -1\n",
    "    ss(rh=8)\n",
    "    imagesc(w, cmap='bwr')\n",
    "    for ii in range(num_layers):\n",
    "        plt.plot(np.ones(2)*(start_n-0.5)+ii*num_subs, [-0.5, NC-0.5],'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521b23a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quick_readout_display(LUMmods2[2].get_weights(ffnet_target=1), 4, num_subs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5117ebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn4b = deepcopy(LUMmods2[2])\n",
    "cnn4b.networks[1].layers[0].sample = True\n",
    "cnn4b.networks[1].set_parameters(val=True)\n",
    "cnn4b.fit( data, **adam_parsT, verbose=2, seed=ii )\n",
    "LLs = cnn4b.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "print(np.mean(LLsNULL-LLs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = cnn4b.networks[1].layers[0].mu.data.cpu().detach().numpy()\n",
    "musP = utils.grid2pixel(mus, enforce_bounds=True, L=NX, force_int=True)\n",
    "\n",
    "sp2d = np.zeros([NX, NX])\n",
    "for cc in range(NCv):\n",
    "    sp2d[musP[cc,0], musP[cc,1]] += 1\n",
    "\n",
    "    imagesc(sp2d, aspect=1, cmap='bwr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3a96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0e273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292604a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LUMmods2[3].plot_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLs = LUMmods2[2].eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "print(np.mean(LLsNULL-LLs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822f96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5s always put in oriented RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df466eeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LGNlags = 10\n",
    "LGNsubs = 4\n",
    "fw0 = 7\n",
    "\n",
    "proj_width = 15\n",
    "\n",
    "#num_lags=14\n",
    "Treg = 0.01\n",
    "Xreg = 0.00001\n",
    "Mreg = 0.0001\n",
    "Creg = None\n",
    "Dreg = 0.5\n",
    "Gnet = 0.005\n",
    "\n",
    "num_iter = 4\n",
    "num_subs = 30\n",
    "fwI = 5\n",
    "\n",
    "LGNpars = STconvLayer.layer_dict( \n",
    "    input_dims = data.stim_dims, num_filters=LGNsubs, bias=False, norm_type=1,\n",
    "    filter_dims=[1,fw0,fw0,LGNlags] , NLtype='relu', initialize_center=True)\n",
    "LGNpars['output_norm']='batch'\n",
    "LGNpars['window']='hamming'\n",
    "LGNpars['reg_vals'] = {'d2x':Xreg, 'd2t':Treg, 'center': Creg, 'edge_t':100}  \n",
    "\n",
    "proj_pars = ConvLayer.layer_dict( \n",
    "    num_filters=num_subs, bias=False, norm_type=1, num_inh=num_subs//2,\n",
    "    filter_dims=proj_width, NLtype='lin', initialize_center=True)\n",
    "proj_pars['output_norm']='batch'\n",
    "proj_pars['window']='hamming'\n",
    "\n",
    "Ilayers = IterSTlayer.layer_dict(    \n",
    "    num_filters=num_subs, bias=False, num_iter=num_iter, output_config='full',\n",
    "    pos_constraint=True, \n",
    "    norm_type=1, num_inh=num_subs//2, filter_width=fwI, num_lags=3, \n",
    "    NLtype='relu', initialize_center=False) \n",
    "Ilayers['output_norm'] = 'batch'\n",
    "# Ilayers['reg_vals'] = {'glocal': Gnet}  \n",
    "        \n",
    "scaffold_net =  FFnetwork.ffnet_dict(\n",
    "    ffnet_type='scaffold', xstim_n = 'stim', layer_list=[LGNpars, proj_pars, Ilayers], scaffold_levels=[1,2] )\n",
    "\n",
    "cnn_iter = NDN.NDN( ffnet_list = [scaffold_net, readout_net, drift_net, comb_net], loss_type='poisson')\n",
    "cnn_iter.block_sample = True\n",
    "\n",
    "## Network 1: readout: fixed mus / sigmas\n",
    "cnn_iter.networks[1].layers[0].sample = False\n",
    "#cnnI1.networks[1].layers[0].mu.data = deepcopy(cnn0x.networks[1].layers[0].mu.data)\n",
    "cnn_iter.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "cnn_iter.networks[1].set_parameters(val=False, name='mu')\n",
    "cnn_iter.networks[1].set_parameters(val=False, name='sigma')\n",
    "\n",
    "## Network 2: drift: not fit\n",
    "cnn_iter.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "cnn_iter.networks[2].set_parameters(val=False)\n",
    "\n",
    "## Network 3: Comb\n",
    "cnn_iter.networks[-1].set_parameters(val=False, name='weight')\n",
    "cnn_iter.fit( data, **adam_parsT, verbose=2, )\n",
    "LLs = cnn_iter.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "print(np.mean(LLsNULL-LLs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee857b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32335bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
