{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T22:06:03.217937Z",
     "start_time": "2023-08-17T22:06:03.083603Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "# NDN tools\n",
    "import NDNT.utils as utils # some other utilities\n",
    "import NDNT.NDNT as NDN\n",
    "from NDNT.modules.layers import *\n",
    "from NDNT.networks import *\n",
    "\n",
    "from ColorDataUtils.multidata_utils import MultiExperiment\n",
    "from NDNT.utils import imagesc   # because I'm lazy\n",
    "\n",
    "device = torch.device(\"cuda:1\")\n",
    "dtype = torch.float32\n",
    "\n",
    "datadir = '/home/dbutts/ColorV1/Data/'\n",
    "dirname = '/home/dbutts/ColorV1/CLRworkspace/'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93d8f63d4b0ee9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf3a84bdb13616f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T22:07:08.339975Z",
     "start_time": "2023-08-17T22:06:03.700634Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FILE_INFO: stim_locsLP list again -- ok but output check\n",
      "  Disjoint data exists with this eye_config -- trunctating to first section.\n",
      "  FILE_INFO: stim_locsLP list again -- ok but output check\n",
      "  Disjoint data exists with this eye_config -- trunctating to first section.\n",
      "153120 total time steps, 444 units\n",
      "J220718 48.2% fixations remaining\n",
      "J220727 37.7% fixations remaining\n",
      "  Stim expansion for shift: [920, 500, 1012, 592]\n",
      "  Writing lam stim 0: overlap 44, 35\n",
      "  Writing lam stim 1: overlap 44, 57\n",
      "  Writing lam stim 2: overlap 48, 57\n",
      "  Writing lam stim 3: overlap 48, 35\n",
      "  Adding fixation point\n",
      "  Shifting stim...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 20/20 [00:12<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CROP: New stim size: 52 x 52\n",
      "  Done: expt 0\n",
      "  Stim expansion for shift: [975, 530, 1067, 622]\n",
      "  Writing lam stim 0: overlap 10, 8\n",
      "  Writing lam stim 1: overlap 10, 60\n",
      "  Writing lam stim 2: overlap 60, 60\n",
      "  Writing lam stim 3: overlap 60, 8\n",
      "  Shifting stim...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 11/11 [00:09<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CROP: New stim size: 52 x 52\n",
      "  Done: expt 1\n",
      "Stimulus assembly complete\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "num_lags=16\n",
    "#expt_names = ['J220715','J220722','J220801','J220808']\n",
    "expt_names = ['J220718', 'J220727']\n",
    "expts = MultiExperiment(expt_names)\n",
    "data, drift_terms, mu0s = expts.load(datadir,\n",
    "                                     num_lags=num_lags,\n",
    "                                     et_metric_thresh=0.8,\n",
    "                                     array_types=['LP', 'LP'],\n",
    "                                     luminance_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ab0022c784cba1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T22:07:13.562965Z",
     "start_time": "2023-08-17T22:07:13.418936Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGfCAYAAAD/BbCUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAn2ElEQVR4nO3df3BU1f3/8dcmJhvAsIrCbvIh0LQGlYCMgo3EH1iVTDOtI0PHqvixWOfbgQasKXbQyLcVHL4J4JTBmSCdUAdxOpT+IbTO+IvMKKGdDNNAcWTQUjpEjJU1xQ8mEZKNJOf7h8N+GoOQc9l7cnfzfMzsjLl7795z9iT42rP3fU/IGGMEAADgSNZwNwAAAIwshA8AAOAU4QMAADhF+AAAAE4RPgAAgFOEDwAA4BThAwAAOEX4AAAAThE+AACAU4QPAADg1CV+vfDzzz+vZ599VsePH1dpaak2bNigW2+99YLH9ff36+OPP1Z+fr5CoZBfzQMAAClkjFFXV5cKCwuVlXWBuQ3jg+3bt5ucnByzefNm895775nHHnvMjBkzxhw7duyCx7a1tRlJPHjw4MGDB480fLS1tV3w//UhY1K/sFxZWZluuOEGbdq0Kbnt2muv1bx581RXV3feYzs6OnTZZZepZNGvlJ2bl+qmBZphoic4GIuRxcF42/5990T7/WkI4JP+nh59tHK1PvvsM0UikfPum/KvXXp7e7V//349+eSTA7ZXVFSoubl50P6JREKJRCL5c1dXlyQpOzdP2WHCB4YJYzGyBDB8ZOURPpCehnLJRMovOD1x4oT6+voUjUYHbI9Go4rH44P2r6urUyQSST6KiopS3SQAABAgvlW7fDX5GGPOmYZqamrU0dGRfLS1tfnVJAAAEAAp/9rlyiuvVHZ29qBZjvb29kGzIZIUDocVDocHbT9VmlDWqKHNU5ozHuZMz9jlrlCfl3PYHZN1xu7lQx76Heqz29+2TV+ew65dIdt+e5iNtn5vLd8nL8dk2Z7DS7/77C7p8vLe2rYrZHuVWcqvSksN635Y6o75+/rAcEr5zEdubq5mzpypxsbGAdsbGxtVXl6e6tMBAIA048t9PpYtW6aHHnpIs2bN0uzZs9XQ0KAPP/xQixcv9uN0AAAgjfgSPu677z59+umneuaZZ3T8+HFNmzZNr732miZPnuzH6QAAQBrx7Q6nVVVVqqqq8uvlAQBAmmJtFwAA4JRvMx8XK/+dsLLPUQVzLsZDhDLZ/u4v2bfL9iZEXvrt5OZZtv2wfW899LvP9hwOKizcVH1YVh55OYflMU76bXmMdeWRZF/lY11JFNAyHyAFmPkAAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE4FttrlizFS/9CKXTytR+HiinvbNUuybK+e97L+iO9X6Euhfn/XEwnk+iOZwsvvuc9/S0EdC9vqNCeVZkCaYOYDAAA4RfgAAABOET4AAIBThA8AAOAU4QMAADgV2GqXUSeMsnN9vMzdxRX3tudwUYli/K1EkZQR1QzWlQyS/Zo21mv/2DfK+hxe1knyeQ0jLx+RgrhOksmy7XgA/zCAFGHmAwAAOEX4AAAAThE+AACAU4QPAADgFOEDAAA4Fdhql77ckJQ7xKvDPUSo/mzLA1xUATipTLC84t5D1YexfG/d9NuyciBDYrmnqh1Lflcruag88sS631SvAGdlyD+xAAAgXRA+AACAU4QPAADgFOEDAAA4RfgAAABOBbbaJeuMUZZthYKFbBcXnvt8jsCuu2J7jIPKBOuKCS9VPn73w0UFRxCN0CKRk9OGuwWAf5j5AAAAThE+AACAU4QPAADgFOEDAAA4RfgAAABOBbbapTcSUnZ4iJf3j9Cr4Z1wUfURxGoXL0ZqNYolJ2Phgu/94B82ZC5mPgAAgFOEDwAA4BThAwAAOEX4AAAAThE+AACAU4Gtdtlb9VuNzR9aNjrRd8r69f/dZ3ep+r/7R9uf48xYq/3jZyJW+5/4It9qf0n69IsxdudIXGp9js96R1nt35nIs9q/qydstb8kdffkWO1/xnJ/STI92Vb7Z/XYZf/sHvvyiuzTdsdkJ6xPoexeywMs1yTysr5QECuubM+RuMKfZgBBwMwHAABwivABAACcInwAAACnCB8AAMApwgcAAHAqsNUu5c/9H2WH7aogfDVSl1nIkH7b1d+IdVps2L5Xlh95XPwKulhvxkvVDpCpmPkAAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE5ZV7vs2bNHzz77rPbv36/jx49r586dmjdvXvJ5Y4xWrVqlhoYGnTx5UmVlZdq4caNKS0utzhPq+/LhFxdXt/tdMRGyXCPD0zGezmF3Wb9tmzxVDbioNPB5vD39zloekwl/F5JkQg5OYlu1w0c9IMn6z+HUqVOaMWOG6uvrz/n8unXrtH79etXX16ulpUWxWExz585VV1fXRTcWAACkP+uZj8rKSlVWVp7zOWOMNmzYoBUrVmj+/PmSpK1btyoajWrbtm1atGjRoGMSiYQSif9dSrOzs9O2SQAAII2kdCKwtbVV8XhcFRUVyW3hcFhz5sxRc3PzOY+pq6tTJBJJPoqKilLZJAAAEDApDR/xeFySFI1GB2yPRqPJ576qpqZGHR0dyUdbW1sqmwQAAALGl9urh75ysZcxZtC2s8LhsMLhsB/NAAAAAZTS8BGLxSR9OQNSUFCQ3N7e3j5oNuRCcj43yu4dWomC8dCLfstjTLb91fP257B8/Vy7/SVHV9xblkxYV684qHbJmHU4gtgPFxU4tufw8Hdhe4zt3zeQyVL6v6Li4mLFYjE1NjYmt/X29qqpqUnl5eWpPBUAAEhT1nMGn3/+uf75z38mf25tbdU777yjcePGadKkSaqurlZtba1KSkpUUlKi2tpajR49WgsWLEhpwwEAQHqyDh/79u3Td77zneTPy5YtkyQtXLhQL774opYvX67u7m5VVVUlbzK2a9cu5efnp67VAAAgbYWMMYH6Vrizs1ORSEQz/vv/KTs3b0jHjNRrPrx8h+zmmg+73bnmw0dB7AfXfAxJ4goPtxcGhlF/T48+fPL/qqOjQ2PHjj3vvtzwFwAAOOVLqW0q9IUlDbWaw8MnI+u1Hzx8CMn6wvIA2/09fKr1e90VyX5Nnqwzlvv32Xfcvk3257Duh+U5Ql7a9IXdAHp6b23PccZu/5Dl/pIU+sJuwL2cQ1/YDXjojF2b/v5ozGp/IJ0w8wEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnApstUvHNf3KGuVjnbtthYynihrbm0vYn2NECur75Ps9Nbx03MGCIkEdjzSX1T3cLQD8w8wHAABwivABAACcInwAAACnCB8AAMApwgcAAHAqsNUuV+7PUnbu0LKRi9VdnZzDuk32ZQZ+t8nrMVYCWl3hafXVDOD3qsSe1heyPMbLOWzXe7JdN+eza4K4JDGQGsx8AAAApwgfAADAKcIHAABwivABAACcInwAAACnAlvt0lUUUnY4QOUDAWqKUw76bV0l4qUCx3otH/tKA98riTytL2R5gKfqJrv3yrrfXtqUbTl+DvptO35Z3Xw2RObitxsAADhF+AAAAE4RPgAAgFOEDwAA4FRgLzgt2NujS4bYOpPl4Dbjnm5lbnuFmc+vL/vbxDt5by3P0e/kdvrBu3W9p9vWW3bD0+30Qz5flezp5f2/UtrvfneWeLnnO5AemPkAAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE4Fttrlf6bmKTs3z78T2N892/dzhPrtDgh5uBje9phQn4Nz2I6Fi7HzwHo8rH8/LF9f9rdXD2JhifUt4r0I4m3lgQzGnwMAAHCK8AEAAJwifAAAAKcIHwAAwCnCBwAAcCqw1S6j/t2vS3KGdnm/l6vhra8893IO63U1HFzW76JywLaKw1ge4KHaxUVFjfU5bAW0yieQbP/2XPxduDgHkCaY+QAAAE4RPgAAgFOEDwAA4BThAwAAOEX4AAAATgW22qX30pD6cgN0ebiXpmTCmhcOhDKlI7aoXvFPAH+l7H/N+QVB5mLmAwAAOEX4AAAAThE+AACAU4QPAADgFOEDAAA4ZVXtUldXpx07dujvf/+7Ro0apfLycq1du1ZXX311ch9jjFatWqWGhgadPHlSZWVl2rhxo0pLS60admZ0SCYcwEvWg8TFxfBehiCAF+n7vu6KFMh+B7Hqw1oQ31fJQbuC2nHg4lnNfDQ1NWnJkiXau3evGhsbdebMGVVUVOjUqVPJfdatW6f169ervr5eLS0tisVimjt3rrq6ulLeeAAAkH6sZj7eeOONAT9v2bJFEyZM0P79+3XbbbfJGKMNGzZoxYoVmj9/viRp69atikaj2rZtmxYtWpS6lgMAgLR0Udd8dHR0SJLGjRsnSWptbVU8HldFRUVyn3A4rDlz5qi5ufmcr5FIJNTZ2TngAQAAMpfn8GGM0bJly3TLLbdo2rRpkqR4PC5JikajA/aNRqPJ576qrq5OkUgk+SgqKvLaJAAAkAY8h4+lS5fq3Xff1e9///tBz4VCA69yM8YM2nZWTU2NOjo6ko+2tjavTQIAAGnA09oujz76qF555RXt2bNHEydOTG6PxWKSvpwBKSgoSG5vb28fNBtyVjgcVjgcHrT982/0Kyuv30vzACDtXXI6E0qV4CcXy2LZVAr29wy9QVYzH8YYLV26VDt27NBbb72l4uLiAc8XFxcrFoupsbExua23t1dNTU0qLy+3ORUAAMhQVjMfS5Ys0bZt2/SnP/1J+fn5yes4IpGIRo0apVAopOrqatXW1qqkpEQlJSWqra3V6NGjtWDBAl86AAAA0otV+Ni0aZMk6fbbbx+wfcuWLXr44YclScuXL1d3d7eqqqqSNxnbtWuX8vPzU9JgAACQ3qzChzEX/vInFApp5cqVWrlypdc2AQCADMbaLgAAwClP1S4AAH9l9dqXMhjbj5MeFj2yPYff+0uyX8PIRSGRi2JNB/3utzim36LPzHwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKeodgGAAMrpsj/GurIk2/+KGvs22e3v5RiT5aHKx/oclifwMBUQtLVdbPZl5gMAADhF+AAAAE4RPgAAgFOEDwAA4BThAwAAOEW1CwAEUM+V9hUZLtb6sG6VizbZHuOh2sWWdZtcrDfj83j39w99b2Y+AACAU4QPAADgFOEDAAA4RfgAAABOET4AAIBTVLsAQABddtj+GOv1RJxUlli+vpc1TmzPEfJwEp8/qgdtnZYki2P6eof+JjHzAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcotoFAALodIF9+YOLiglrDtrkZB0Vy2Ns2+SpEsWW39UuiaHvy8wHAABwivABAACcInwAAACnCB8AAMApwgcAAHCKahcACKC+PA8H2VYzuKiwcMFBtYvflURehsK6QsbnaheTPfR9mfkAAABOET4AAIBThA8AAOAU4QMAADhF+AAAAE5R7QIAAWSy7EsTnKxxYsvnNVFGssBVu/QNfWdmPgAAgFOEDwAA4BThAwAAOEX4AAAAThE+AACAU1S7AEAAOan6cLG2i+U5Qh4+Ejt5rwJYSRS0pXlM39D3ZeYDAAA4RfgAAABOET4AAIBThA8AAOAU4QMAADhlVe2yadMmbdq0SR988IEkqbS0VL/61a9UWVkpSTLGaNWqVWpoaNDJkydVVlamjRs3qrS0NOUNB4BMdmaMfS2Dk7U+AsjYfoz2Uolie4yDsQj1257DvuM2v1M242A1ZBMnTtSaNWu0b98+7du3T3fccYfuueceHTp0SJK0bt06rV+/XvX19WppaVEsFtPcuXPV1dVlcxoAAJDBQsaYi8q+48aN07PPPqtHHnlEhYWFqq6u1hNPPCFJSiQSikajWrt2rRYtWnTO4xOJhBKJRPLnzs5OFRUVadKa1crKy7uYpgFA+vLySZiZj6Fh5mPo57BoV39Pjz745Qp1dHRo7Nix593X8zUffX192r59u06dOqXZs2ertbVV8XhcFRUVyX3C4bDmzJmj5ubmr32duro6RSKR5KOoqMhrkwAAQBqwDh8HDx7UpZdeqnA4rMWLF2vnzp2aOnWq4vG4JCkajQ7YPxqNJp87l5qaGnV0dCQfbW1ttk0CAABpxPr26ldffbXeeecdffbZZ3r55Ze1cOFCNTU1JZ8PhQZO6xhjBm37T+FwWOFw2LYZAAAgTVmHj9zcXF111VWSpFmzZqmlpUXPPfdc8jqPeDyugoKC5P7t7e2DZkMAAOeX0+X/nRCsrxHxwMm6Ky64eLMsBe69TVx4l7Mu+rfbGKNEIqHi4mLFYjE1NjYmn+vt7VVTU5PKy8sv9jQAACBDWM18PPXUU6qsrFRRUZG6urq0fft27d69W2+88YZCoZCqq6tVW1urkpISlZSUqLa2VqNHj9aCBQv8aj8AAEgzVuHjk08+0UMPPaTjx48rEonouuuu0xtvvKG5c+dKkpYvX67u7m5VVVUlbzK2a9cu5efn+9J4AACQfi76Ph+p1tnZqUgkwn0+AIxoOZ1c8xEoXPNxQf09PTq62uf7fAAAAHhhXe0CAPBf3yj7T9pB+yQsOZowsL3TZwB5GjoH763VXVT9WtsFAADgYhE+AACAU4QPAADgFOEDAAA4RfgAAABOUe0CAAGU928P9Q+WhwSxOiZj2L63HipXrCuJvFTHWBzTlxh6p5n5AAAAThE+AACAU4QPAADgFOEDAAA4RfgAAABOUe0CAAGUdWa4W5AaTipqMqFqx0G1S6jPwzks1nYJ9Q59X2Y+AACAU4QPAADgFOEDAAA4RfgAAABOET4AAIBTVLsAQADlfO6h/MH2EAdVItbVLkFskwcu1l2xqUTxsr/tMVm9Q+8EMx8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCmqXQAggBKXuSjJ8P8UQax2gT/6EkMfPGY+AACAU4QPAADgFOEDAAA4RfgAAABOET4AAIBTVLsAQAD1jvWw2Icl6/VHXHCx8EoQuRgMD++tzdoufRZdYOYDAAA4RfgAAABOET4AAIBThA8AAOAU4QMAADhFtQsABNDo+Ait+nDBQ2FJyASwNMi6SfZ9sCnC6esd+s7MfAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAAp6h2AYAAMtnD3YLUsF5OxEuRj5PCIJ9P4qWYxvIYT8vH2FS7WAw2Mx8AAMApwgcAAHCK8AEAAJwifAAAAKcuKnzU1dUpFAqpuro6uc0Yo5UrV6qwsFCjRo3S7bffrkOHDl1sOwEAQIbwXO3S0tKihoYGXXfddQO2r1u3TuvXr9eLL76oKVOmaPXq1Zo7d64OHz6s/Pz8i24wAIwE2QkPpQkBq37wsr+nNo1QQaskCvm9tsvnn3+uBx98UJs3b9bll1+e3G6M0YYNG7RixQrNnz9f06ZN09atW3X69Glt27bNy6kAAECG8RQ+lixZou9973u66667BmxvbW1VPB5XRUVFcls4HNacOXPU3Nx8ztdKJBLq7Owc8AAAAJnL+muX7du3629/+5taWloGPRePxyVJ0Wh0wPZoNKpjx46d8/Xq6uq0atUq22YAAIA0ZTXz0dbWpscee0y/+93vlJeX97X7hUIDvyQyxgzadlZNTY06OjqSj7a2NpsmAQCANGM187F//361t7dr5syZyW19fX3as2eP6uvrdfjwYUlfzoAUFBQk92lvbx80G3JWOBxWOBz20nYAAJCGrMLHnXfeqYMHDw7Y9uMf/1jXXHONnnjiCX3zm99ULBZTY2Ojrr/+eklSb2+vmpqatHbt2tS1GgAy3BdjnCxYYs/vJU6C2u0MqMLx9N5aHNOXGPrOVuEjPz9f06ZNG7BtzJgxuuKKK5Lbq6urVVtbq5KSEpWUlKi2tlajR4/WggULbE4FAAAyVMpXtV2+fLm6u7tVVVWlkydPqqysTLt27eIeHwAAQJIUMsYEajKps7NTkUhEk9asVtZ5LmoFgEw2pi2gq1/wtUva8v9rlx4dfu4pdXR0aOzYsefdN6C/3QAAIFMRPgAAgFMpv+YDAHDxshPD3YKvEdCvRXzn99cuDr7WCfl8lUWW32u7AAAAeEX4AAAAThE+AACAU4QPAADgFOEDAAA4RbULAATQ6VhA72rld7UL1TS+HeP3jdL6eoa+LzMfAADAKcIHAABwivABAACcInwAAACnCB8AAMApql0AIID6c4a7BZnLU0FNANd2sa1eMf3257Bi8cYy8wEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnKLaBQACKO9/HCxyEsTlYzx021geY1x87A7gGjW275O1xNBPwMwHAABwivABAACcInwAAACnCB8AAMApwgcAAHCKahcAyBQuqlcsz2G7/ogXASwssa4scfE+eWLRrlBi6Psy8wEAAJwifAAAAKcIHwAAwCnCBwAAcIoLTgEggLIsLt47K9RvuX+fl3PYXRmZZXsOyz54OYft+/TlMZZXhNpemOupTZb7e7io1abfZ74Y+kAw8wEAAJwifAAAAKcIHwAAwCnCBwAAcIrwAQAAnKLaBQACqGe8l9KE1LcjLdi+VV7eWtv7pdvy+/Xl8RbuFsf09WQPeV9mPgAAgFOEDwAA4BThAwAAOEX4AAAAThE+AACAU1S7AEAA9ef6fw4HBRb2JRYe2mTdj0B+7PZQiuKiysdi/Zj+nKHvHMghAAAAmYvwAQAAnCJ8AAAApwgfAADAKcIHAABwyqraZeXKlVq1atWAbdFoVPF4XJJkjNGqVavU0NCgkydPqqysTBs3blRpaWnqWgwAI4CnSpQsu3IG4+Hjp/UxttUuXj4SO6jaMX5X7bhYb8ZLQY3FMf39Q9/ZephLS0t1/Pjx5OPgwYPJ59atW6f169ervr5eLS0tisVimjt3rrq6umxPAwAAMpR1+LjkkksUi8WSj/Hjx0v6ctZjw4YNWrFihebPn69p06Zp69atOn36tLZt25byhgMAgPRkHT6OHDmiwsJCFRcX6/7779fRo0clSa2trYrH46qoqEjuGw6HNWfOHDU3N3/t6yUSCXV2dg54AACAzGUVPsrKyvTSSy/pzTff1ObNmxWPx1VeXq5PP/00ed1HNBodcMx/XhNyLnV1dYpEIslHUVGRh24AAIB0YRU+Kisr9YMf/EDTp0/XXXfdpVdffVWStHXr1uQ+odDAC2CMMYO2/aeamhp1dHQkH21tbTZNAgAAaeai1nYZM2aMpk+friNHjmjevHmSpHg8roKCguQ+7e3tg2ZD/lM4HFY4HL6YZgBAxhnV7qGE4zwf9FLF9/VgXKzt4kIQ2+SFRbVLXyJ7yPte1H0+EomE3n//fRUUFKi4uFixWEyNjY3J53t7e9XU1KTy8vKLOQ0AAMggVjMfv/jFL3T33Xdr0qRJam9v1+rVq9XZ2amFCxcqFAqpurpatbW1KikpUUlJiWprazV69GgtWLDAr/YDAIA0YxU+PvroIz3wwAM6ceKExo8fr5tuukl79+7V5MmTJUnLly9Xd3e3qqqqkjcZ27Vrl/Lz831pPAAASD8hY2zuX+a/zs5ORSIRTVqzWll5ecPdHAAYFqM/9vCtuJM7ffp8Aq75CBaraz56dOTXT6mjo0Njx449776s7QIAAJy6qGoXAIA/snrtj7FdfsQJ2yVRgtgHD6xnYzJgpiQrYbGvf80AAAAYjPABAACcInwAAACnCB8AAMApwgcAAHCKahcACKBQ/3C34Nx8r0bJkGoX6+KVgPbbqmrHog/MfAAAAKcIHwAAwCnCBwAAcIrwAQAAnCJ8AAAAp6h2AYAA8lTtEsCKiVCwFk53xoQyYLEWSTbdsKmEYuYDAAA4RfgAAABOET4AAIBThA8AAOAU4QMAADhFtQsABFC/h3+dbdddsVq3w6sMqfqw5qDIx/d1diSrftj8PjHzAQAAnCJ8AAAApwgfAADAKcIHAABwivABAACcotoFAAIo76R9KYN19YqDQhQnFTUBFMzKI/tDbNoV6h16p5n5AAAAThE+AACAU4QPAADgFOEDAAA4RfgAAABOUe0CAAHU+U0PpQn9drt7WhvE9hyW+3thew4n/bY8h6f3KWDn6Mse+u8sMx8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwCmqXQAggPpzvJRk2PG0nsgIXavFdx6G27pqx8uvlMUx/T2s7QIAAAKK8AEAAJwifAAAAKcIHwAAwCnCBwAAcIpqFwAIoKxeB2UlVK4Eh5dqF9u1WvwuoLL4nWXmAwAAOEX4AAAAThE+AACAU4QPAADgFOEDAAA4ZV3t8q9//UtPPPGEXn/9dXV3d2vKlCl64YUXNHPmTEmSMUarVq1SQ0ODTp48qbKyMm3cuFGlpaUpbzwAZKq+sP9ru7iodrFePyag6814WgfHhvVCLR546IRNRY3NekRWMx8nT57UzTffrJycHL3++ut677339Otf/1qXXXZZcp9169Zp/fr1qq+vV0tLi2KxmObOnauuri6bUwEAgAxlNfOxdu1aFRUVacuWLclt3/jGN5L/bYzRhg0btGLFCs2fP1+StHXrVkWjUW3btk2LFi0a9JqJREKJRCL5c2dnp20fAABAGrGa+XjllVc0a9Ys3XvvvZowYYKuv/56bd68Ofl8a2ur4vG4KioqktvC4bDmzJmj5ubmc75mXV2dIpFI8lFUVOSxKwAAIB1YhY+jR49q06ZNKikp0ZtvvqnFixfrZz/7mV566SVJUjwelyRFo9EBx0Wj0eRzX1VTU6OOjo7ko62tzUs/AABAmrD62qW/v1+zZs1SbW2tJOn666/XoUOHtGnTJv3oRz9K7hcKDbyoxRgzaNtZ4XBY4XDYtt0AACBNWYWPgoICTZ06dcC2a6+9Vi+//LIkKRaLSfpyBqSgoCC5T3t7+6DZEADA17vktIsSDv9PgaEJ+V5O43/FTl/Cp7Vdbr75Zh0+fHjAtn/84x+aPHmyJKm4uFixWEyNjY3J53t7e9XU1KTy8nKbUwEAgAxlNfPx85//XOXl5aqtrdUPf/hD/fWvf1VDQ4MaGhokffl1S3V1tWpra1VSUqKSkhLV1tZq9OjRWrBggS8dAAAA6cUqfNx4443auXOnampq9Mwzz6i4uFgbNmzQgw8+mNxn+fLl6u7uVlVVVfImY7t27VJ+fn7KGw8AANJPyBgTqG/9Ojs7FYlENGnNamXl5Q13cwBgWIQ/dbD6RaD+9R/ZAnqDUyt9iR7989mn1NHRobFjx553X+vbq/vtbBbq7+kZ5pYAwPDpSxA+RpJMCB/9iS//vz2UOY3AzXx89NFH3GgMAIA01dbWpokTJ553n8CFj/7+fn388cfKz88fdG+Qzs5OFRUVqa2t7YJTOpmEftPvkYB+0++RIJP7bYxRV1eXCgsLlZV1/pm7wH3tkpWVdcHENHbs2IwbtKGg3yML/R5Z6PfIkqn9jkQiQ9rPwZeKAAAA/4vwAQAAnEqr8BEOh/X000+PuLVg6Df9HgnoN/0eCUZqv78qcBecAgCAzJZWMx8AACD9ET4AAIBThA8AAOAU4QMAADhF+AAAAE6lTfh4/vnnVVxcrLy8PM2cOVN//vOfh7tJvlq5cqVCodCARywWG+5mpdyePXt09913q7CwUKFQSH/84x8HPG+M0cqVK1VYWKhRo0bp9ttv16FDh4ansSl0oX4//PDDg8b/pptuGp7GplBdXZ1uvPFG5efna8KECZo3b54OHz48YJ9MHPOh9DsTx3zTpk267rrrknfznD17tl5//fXk85k41tKF+52JY20rLcLHH/7wB1VXV2vFihU6cOCAbr31VlVWVurDDz8c7qb5qrS0VMePH08+Dh48ONxNSrlTp05pxowZqq+vP+fz69at0/r161VfX6+WlhbFYjHNnTtXXV1djluaWhfqtyR997vfHTD+r732msMW+qOpqUlLlizR3r171djYqDNnzqiiokKnTp1K7pOJYz6UfkuZN+YTJ07UmjVrtG/fPu3bt0933HGH7rnnnmTAyMSxli7cbynzxtqaSQPf/va3zeLFiwdsu+aaa8yTTz45TC3y39NPP21mzJgx3M1wSpLZuXNn8uf+/n4Ti8XMmjVrktt6enpMJBIxv/nNb4ahhf74ar+NMWbhwoXmnnvuGZb2uNTe3m4kmaamJmPMyBnzr/bbmJEz5pdffrn57W9/O2LG+qyz/TZm5Iz1+QR+5qO3t1f79+9XRUXFgO0VFRVqbm4epla5ceTIERUWFqq4uFj333+/jh49OtxNcqq1tVXxeHzA2IfDYc2ZMyfjx16Sdu/erQkTJmjKlCn6yU9+ovb29uFuUsp1dHRIksaNGydp5Iz5V/t9ViaPeV9fn7Zv365Tp05p9uzZI2asv9rvszJ5rIcicKvaftWJEyfU19enaDQ6YHs0GlU8Hh+mVvmvrKxML730kqZMmaJPPvlEq1evVnl5uQ4dOqQrrrhiuJvnxNnxPdfYHzt2bDia5ExlZaXuvfdeTZ48Wa2trfrlL3+pO+64Q/v378+Y2zIbY7Rs2TLdcsstmjZtmqSRMebn6reUuWN+8OBBzZ49Wz09Pbr00ku1c+dOTZ06NRkwMnWsv67fUuaOtY3Ah4+zQqHQgJ+NMYO2ZZLKysrkf0+fPl2zZ8/Wt771LW3dulXLli0bxpa5N9LGXpLuu+++5H9PmzZNs2bN0uTJk/Xqq69q/vz5w9iy1Fm6dKneffdd/eUvfxn0XCaP+df1O1PH/Oqrr9Y777yjzz77TC+//LIWLlyopqam5POZOtZf1++pU6dm7FjbCPzXLldeeaWys7MHzXK0t7cPSsyZbMyYMZo+fbqOHDky3E1x5mx1z0gfe0kqKCjQ5MmTM2b8H330Ub3yyit6++23NXHixOT2TB/zr+v3uWTKmOfm5uqqq67SrFmzVFdXpxkzZui5557L+LH+un6fS6aMtY3Ah4/c3FzNnDlTjY2NA7Y3NjaqvLx8mFrlXiKR0Pvvv6+CgoLhboozxcXFisViA8a+t7dXTU1NI2rsJenTTz9VW1tb2o+/MUZLly7Vjh079NZbb6m4uHjA85k65hfq97lkyph/lTFGiUQiY8f665zt97lk6lif13Bd6Wpj+/btJicnx7zwwgvmvffeM9XV1WbMmDHmgw8+GO6m+ebxxx83u3fvNkePHjV79+413//+901+fn7G9bmrq8scOHDAHDhwwEgy69evNwcOHDDHjh0zxhizZs0aE4lEzI4dO8zBgwfNAw88YAoKCkxnZ+cwt/zinK/fXV1d5vHHHzfNzc2mtbXVvP3222b27Nnmv/7rv9K+3z/96U9NJBIxu3fvNsePH08+Tp8+ndwnE8f8Qv3O1DGvqakxe/bsMa2trebdd981Tz31lMnKyjK7du0yxmTmWBtz/n5n6ljbSovwYYwxGzduNJMnTza5ubnmhhtuGFCilonuu+8+U1BQYHJyckxhYaGZP3++OXTo0HA3K+XefvttI2nQY+HChcaYL0svn376aROLxUw4HDa33XabOXjw4PA2OgXO1+/Tp0+biooKM378eJOTk2MmTZpkFi5caD788MPhbvZFO1efJZktW7Yk98nEMb9QvzN1zB955JHkv9vjx483d955ZzJ4GJOZY23M+fudqWNtK2SMMe7mWQAAwEgX+Gs+AABAZiF8AAAApwgfAADAKcIHAABwivABAACcInwAAACnCB8AAMApwgcAAHCK8AEAAJwifAAAAKcIHwAAwKn/D4r/gOEfIxL4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imagesc(drift_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162818dc996c92f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# adam params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5518eca0bf14401b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T22:07:15.908234Z",
     "start_time": "2023-08-17T22:07:15.890805Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, ndn_model, LLs, trial):\n",
    "        self.ndn_model = ndn_model\n",
    "        self.LLs = LLs\n",
    "        self.trial = trial\n",
    "\n",
    "adam_parsT = utils.create_optimizer_params(\n",
    "    optimizer_type='AdamW',\n",
    "    batch_size=2, # * 240 timesteps\n",
    "    num_workers=0,\n",
    "    learning_rate=0.0017,\n",
    "    early_stopping_patience=4,\n",
    "    optimize_graph=False,\n",
    "    weight_decay=0.235,\n",
    "    max_epochs=1)\n",
    "adam_parsT['device'] = device\n",
    "#adam_parsT['accumulated_grad_batches'] = 6\n",
    "\n",
    "# setup\n",
    "data.device = device\n",
    "NCv = data.NC\n",
    "NT = data.robs.shape[0]\n",
    "NA = data.Xdrift.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c239f8d7760e289a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2910a8ebefc3a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T22:07:18.814986Z",
     "start_time": "2023-08-17T22:07:18.796681Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some good starting parameters\n",
    "Treg = 0.01\n",
    "Xreg = 0.000001\n",
    "Mreg = 0.0001\n",
    "Creg = None\n",
    "Dreg = 0.5\n",
    "\n",
    "folder_name = 'models/test_core'\n",
    "num_trials = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca22c21342e19c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# define cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ba5f41bd368f2bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T22:24:15.768930Z",
     "start_time": "2023-08-17T22:24:15.747393Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_model_cnn(trial):\n",
    "    LGNpars = STconvLayer.layer_dict(\n",
    "        input_dims = data.stim_dims,\n",
    "        num_filters=4,\n",
    "        num_inh=2,\n",
    "        bias=False,\n",
    "        norm_type=1,\n",
    "        filter_dims=[1,  # channels\n",
    "                     7,  # width\n",
    "                     7,  # height\n",
    "                     14], # lags\n",
    "        NLtype='relu',\n",
    "        initialize_center=True)\n",
    "    LGNpars['output_norm']='batch'\n",
    "    LGNpars['window']='hamming'\n",
    "    LGNpars['reg_vals'] = {'d2x':Xreg,\n",
    "                           'd2t':Treg,\n",
    "                           'center': Creg, # None\n",
    "                           'edge_t':100} # just pushes the edge to be sharper\n",
    "\n",
    "    num_subs0 = trial.suggest_int('num_subs_l0', 20, 80)\n",
    "    num_subs1 = trial.suggest_int('num_subs_l1', 20, 80)\n",
    "    num_subs2 = trial.suggest_int('num_subs_l2', 20, 80)\n",
    "    num_inh0 = trial.suggest_float('num_inh_l0', 0.1, 0.7)\n",
    "    num_inh1 = trial.suggest_float('num_inh_l1', 0.1, 0.7)\n",
    "    num_inh2 = trial.suggest_float('num_inh_l2', 0.1, 0.7)\n",
    "    conv_l0_filter_width = trial.suggest_int('conv_l0_filter_width', 7, 39, step=2)\n",
    "    conv_l1_filter_width = trial.suggest_int('conv_l1_filter_width', 5, 39, step=2)\n",
    "    conv_l2_filter_width = trial.suggest_int('conv_l2_filter_width', 3, 39, step=2)\n",
    "\n",
    "    proj_pars = ConvLayer.layer_dict(\n",
    "        num_filters=num_subs0,\n",
    "        bias=False,\n",
    "        norm_type=1,\n",
    "        num_inh=int(num_inh0*num_subs0),\n",
    "        filter_dims=trial.suggest_int('proj_filter_width', 7, 29, step=2),\n",
    "        NLtype=trial.suggest_categorical('proj_NLtype', ['lin', 'relu']),\n",
    "        initialize_center=True)\n",
    "    proj_pars['output_norm']='batch'\n",
    "    proj_pars['window']='hamming'\n",
    "\n",
    "    conv_layer0 = ConvLayer.layer_dict(\n",
    "        num_filters=num_subs0,\n",
    "        num_inh=int(num_inh0*num_subs0),\n",
    "        bias=False,\n",
    "        norm_type=1,\n",
    "        filter_dims=conv_l0_filter_width,\n",
    "        NLtype='relu',\n",
    "        initialize_center=False)\n",
    "    conv_layer0['output_norm'] = 'batch'\n",
    "\n",
    "    conv_layer1 = ConvLayer.layer_dict(\n",
    "        num_filters=num_subs1,\n",
    "        num_inh=int(num_inh1*num_subs1),\n",
    "        bias=False,\n",
    "        norm_type=1,\n",
    "        filter_dims=conv_l1_filter_width,\n",
    "        NLtype='relu',\n",
    "        initialize_center=False)\n",
    "    conv_layer1['output_norm'] = 'batch'\n",
    "\n",
    "    conv_layer2 = ConvLayer.layer_dict(\n",
    "        num_filters=num_subs2,\n",
    "        num_inh=int(num_inh2*num_subs2),\n",
    "        bias=False,\n",
    "        norm_type=1,\n",
    "        filter_dims=conv_l2_filter_width,\n",
    "        NLtype='relu',\n",
    "        initialize_center=False)\n",
    "    conv_layer2['output_norm'] = 'batch'\n",
    "    \n",
    "    scaffold_net =  FFnetwork.ffnet_dict(\n",
    "        ffnet_type='scaffold',\n",
    "        xstim_n='stim',\n",
    "        layer_list=[LGNpars, proj_pars, conv_layer0, conv_layer1, conv_layer2],\n",
    "        scaffold_levels=[1,2])\n",
    "    \n",
    "    ## 1: READOUT\n",
    "    # reads out from a specific location in the scaffold network\n",
    "    # this location is specified by the mus\n",
    "    readout_pars = ReadoutLayer.layer_dict(\n",
    "        num_filters=NCv,\n",
    "        NLtype='lin',\n",
    "        bias=False,\n",
    "        pos_constraint=True)\n",
    "    # for defining how to sample from the mu (location) of the receptive field\n",
    "    readout_pars['gauss_type'] = 'isotropic'\n",
    "    readout_pars['reg_vals'] = {'max': Mreg}\n",
    "    \n",
    "    readout_net = FFnetwork.ffnet_dict(\n",
    "        xstim_n = None,\n",
    "        ffnet_n=[0],\n",
    "        layer_list = [readout_pars],\n",
    "        ffnet_type='readout')\n",
    "    \n",
    "    ## 2: DRIFT\n",
    "    drift_pars = NDNLayer.layer_dict(\n",
    "        input_dims=[1,1,1,NA],\n",
    "        num_filters=NCv,\n",
    "        bias=False,\n",
    "        norm_type=0,\n",
    "        NLtype='lin')\n",
    "    drift_pars['reg_vals'] = {'d2t': Dreg}\n",
    "    \n",
    "    drift_net = FFnetwork.ffnet_dict(xstim_n = 'Xdrift', layer_list = [drift_pars])\n",
    "    \n",
    "    ## 3: COMB \n",
    "    comb_layer = ChannelLayer.layer_dict(\n",
    "        num_filters=NCv,\n",
    "        NLtype='softplus',\n",
    "        bias=True)\n",
    "    comb_layer['weights_initializer'] = 'ones'\n",
    "    \n",
    "    comb_net = FFnetwork.ffnet_dict(\n",
    "        xstim_n = None,\n",
    "        ffnet_n=[1,2],\n",
    "        layer_list=[comb_layer],\n",
    "        ffnet_type='add')\n",
    "    \n",
    "    cnn = NDN.NDN(ffnet_list = [scaffold_net, readout_net, drift_net, comb_net],\n",
    "                  loss_type='poisson')\n",
    "    cnn.block_sample = True\n",
    "    \n",
    "    ## Network 1: readout: fixed mus / sigmas\n",
    "    cnn.networks[1].layers[0].sample = False\n",
    "    # mus and sigmas are the centers and \"widths\" of the receptive field center to start at\n",
    "    cnn.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "    cnn.networks[1].set_parameters(val=False, name='mu')\n",
    "    cnn.networks[1].set_parameters(val=False, name='sigma')\n",
    "    \n",
    "    ## Network 2: drift: not fit\n",
    "    cnn.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "    cnn.networks[2].set_parameters(val=False)\n",
    "    \n",
    "    ## Network 3: Comb\n",
    "    cnn.networks[-1].set_parameters(val=False, name='weight')\n",
    "\n",
    "    return cnn\n",
    "\n",
    "\n",
    "def objective_cnn(trial):\n",
    "    cnn = make_model_cnn(trial)\n",
    "\n",
    "    cnn.fit(data, **adam_parsT, verbose=2)\n",
    "    LLs = cnn.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "\n",
    "    null_adjusted_LLs = expts.LLsNULL-LLs\n",
    "\n",
    "    cnn_model = Model(cnn, null_adjusted_LLs, trial)\n",
    "\n",
    "    with open(folder_name+'/cnn_'+str(trial.number)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(cnn_model, f)\n",
    "\n",
    "    # dump the intermediate study, but this will be off by one trial\n",
    "    with open(folder_name+'/study.pkl', 'wb') as f:\n",
    "        pickle.dump(study, f)\n",
    "\n",
    "    return np.mean(null_adjusted_LLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d23edde78d5fec7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T22:22:33.792089Z",
     "start_time": "2023-08-17T22:22:33.757645Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model passed all checks\n"
     ]
    }
   ],
   "source": [
    "from ColorDataUtils.model_validation import validate_model, MockTrial\n",
    "\n",
    "val_map = {\n",
    "    'proj_NLtype': 'relu',\n",
    "    'proj_filter_width': 15,\n",
    "    'conv_l0_filter_width': 15,\n",
    "    'conv_l1_filter_width': 15,\n",
    "    'conv_l2_filter_width': 15,\n",
    "    'num_subs_l0': 45,\n",
    "    'num_subs_l1': 30,\n",
    "    'num_subs_l2': 15,\n",
    "    'num_inh_l0': 0.4,\n",
    "    'num_inh_l1': 0.4,\n",
    "    'num_inh_l2': 0.4\n",
    "}\n",
    "\n",
    "mock_trial = MockTrial(val_map)\n",
    "model = make_model_cnn(mock_trial)\n",
    "\n",
    "validate_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2293a91e039e08b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# define iter model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "250069efdfab7e83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T22:07:44.941378Z",
     "start_time": "2023-08-17T22:07:44.918073Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_model_iter(trial):\n",
    "    LGNpars = STconvLayer.layer_dict(\n",
    "        input_dims = data.stim_dims,\n",
    "        num_filters=4,\n",
    "        num_inh=2,\n",
    "        bias=False,\n",
    "        norm_type=1,\n",
    "        filter_dims=[1,  # channels\n",
    "                     7,  # width\n",
    "                     7,  # height\n",
    "                     14], # lags\n",
    "        NLtype='relu',\n",
    "        initialize_center=True)\n",
    "    LGNpars['output_norm']='batch'\n",
    "    LGNpars['window']='hamming'\n",
    "    LGNpars['reg_vals'] = {'d2x':Xreg,\n",
    "                           'd2t':Treg,\n",
    "                           'center': Creg, # None\n",
    "                           'edge_t':100} # just pushes the edge to be sharper\n",
    "    \n",
    "    num_subs = trial.suggest_int('num_subs', 10, 50)\n",
    "    num_inh = trial.suggest_float('num_inh', 0.1, 0.7)\n",
    "    proj_pars = ConvLayer.layer_dict(\n",
    "        num_filters=num_subs,\n",
    "        bias=False,\n",
    "        norm_type=1,\n",
    "        num_inh=int(num_inh*num_subs),\n",
    "        filter_dims=trial.suggest_int('proj_filter_width', 7, 29, step=2),\n",
    "        NLtype=trial.suggest_categorical('proj_NLtype', ['lin', 'relu']),\n",
    "        initialize_center=True)\n",
    "    proj_pars['output_norm']='batch'\n",
    "    proj_pars['window']='hamming'\n",
    "    \n",
    "    iter_layer = IterLayer.layer_dict(\n",
    "        num_filters=num_subs,\n",
    "        num_inh=int(num_inh*num_subs),\n",
    "        bias=False,\n",
    "        num_iter=trial.suggest_int('num_iter', 2, 8),\n",
    "        output_config='full',\n",
    "        norm_type=1,\n",
    "        filter_width=trial.suggest_int('iter_filter_width', 7, 47, step=2),\n",
    "        num_lags=2,\n",
    "        NLtype='relu',\n",
    "        initialize_center=False,\n",
    "        res_layer=False)\n",
    "    iter_layer['output_norm'] = 'batch'\n",
    "    \n",
    "    scaffold_net =  FFnetwork.ffnet_dict(\n",
    "        ffnet_type='scaffold',\n",
    "        xstim_n='stim',\n",
    "        layer_list=[LGNpars, proj_pars, iter_layer],\n",
    "        scaffold_levels=[1,2])\n",
    "    \n",
    "    ## 1: READOUT\n",
    "    # reads out from a specific location in the scaffold network\n",
    "    # this location is specified by the mus\n",
    "    readout_pars = ReadoutLayer.layer_dict(\n",
    "        num_filters=NCv,\n",
    "        NLtype='lin',\n",
    "        bias=False,\n",
    "        pos_constraint=True)\n",
    "    # for defining how to sample from the mu (location) of the receptive field\n",
    "    readout_pars['gauss_type'] = 'isotropic'\n",
    "    readout_pars['reg_vals'] = {'max': Mreg}\n",
    "    \n",
    "    readout_net = FFnetwork.ffnet_dict(\n",
    "        xstim_n = None,\n",
    "        ffnet_n=[0],\n",
    "        layer_list = [readout_pars],\n",
    "        ffnet_type='readout')\n",
    "    \n",
    "    ## 2: DRIFT\n",
    "    drift_pars = NDNLayer.layer_dict(\n",
    "        input_dims=[1,1,1,NA],\n",
    "        num_filters=NCv,\n",
    "        bias=False,\n",
    "        norm_type=0,\n",
    "        NLtype='lin')\n",
    "    drift_pars['reg_vals'] = {'d2t': Dreg}\n",
    "    \n",
    "    drift_net = FFnetwork.ffnet_dict(xstim_n = 'Xdrift', layer_list = [drift_pars])\n",
    "    \n",
    "    ## 3: COMB \n",
    "    comb_layer = ChannelLayer.layer_dict(\n",
    "        num_filters=NCv,\n",
    "        NLtype='softplus',\n",
    "        bias=True)\n",
    "    comb_layer['weights_initializer'] = 'ones'\n",
    "    \n",
    "    comb_net = FFnetwork.ffnet_dict(\n",
    "        xstim_n = None,\n",
    "        ffnet_n=[1,2],\n",
    "        layer_list=[comb_layer],\n",
    "        ffnet_type='add')\n",
    "    \n",
    "    cnn = NDN.NDN(ffnet_list = [scaffold_net, readout_net, drift_net, comb_net],\n",
    "                  loss_type='poisson')\n",
    "    cnn.block_sample = True\n",
    "    \n",
    "    ## Network 1: readout: fixed mus / sigmas\n",
    "    cnn.networks[1].layers[0].sample = False\n",
    "    # mus and sigmas are the centers and \"widths\" of the receptive field center to start at\n",
    "    cnn.networks[1].layers[0].mu.data = torch.tensor(mu0s, dtype=torch.float32)\n",
    "    cnn.networks[1].set_parameters(val=False, name='mu')\n",
    "    cnn.networks[1].set_parameters(val=False, name='sigma')\n",
    "    \n",
    "    ## Network 2: drift: not fit\n",
    "    cnn.networks[2].layers[0].weight.data = torch.tensor(drift_terms, dtype=torch.float32)\n",
    "    cnn.networks[2].set_parameters(val=False)\n",
    "    \n",
    "    ## Network 3: Comb\n",
    "    cnn.networks[-1].set_parameters(val=False, name='weight')\n",
    "\n",
    "    return cnn\n",
    "\n",
    "\n",
    "def objective_iter(trial):\n",
    "    cnn = make_model_iter(trial)\n",
    "\n",
    "    cnn.fit(data, **adam_parsT, verbose=2)\n",
    "    LLs = cnn.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
    "\n",
    "    null_adjusted_LLs = expts.LLsNULL-LLs\n",
    "\n",
    "    cnn_model = Model(cnn, null_adjusted_LLs, trial)\n",
    "\n",
    "    with open(folder_name+'/cnn_'+str(trial.number)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(cnn_model, f)\n",
    "\n",
    "    # dump the intermediate study, but this will be off by one trial\n",
    "    with open(folder_name+'/study.pkl', 'wb') as f:\n",
    "        pickle.dump(study, f)\n",
    "\n",
    "    return np.mean(null_adjusted_LLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608092251c531e8c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# run study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b30c6a700fc6422",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T22:07:45.829528Z",
     "start_time": "2023-08-17T22:07:45.799280Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model passed all checks\n"
     ]
    }
   ],
   "source": [
    "from ColorDataUtils.model_validation import validate_model, MockTrial\n",
    "\n",
    "val_map = {\n",
    "    'iter_filter_width': 15,\n",
    "    'num_inh': 0.69,\n",
    "    'num_iter': 7,\n",
    "    'num_subs': 45,\n",
    "    'proj_NLtype': 'relu',\n",
    "    'proj_filter_width': 15,\n",
    "}\n",
    "\n",
    "mock_trial = MockTrial(val_map)\n",
    "model = make_model_iter(mock_trial)\n",
    "\n",
    "validate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecffd3d702259354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T22:08:04.014358Z",
     "start_time": "2023-08-17T22:07:46.550163Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-17 18:07:46,580] A new study created in memory with name: Four datasets w/o initializing LGN weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: M062_CsCX_R_N_A\n",
      "\n",
      "GPU Available: True, GPU Used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|█                                             | 6/255 [00:08<06:05,  1.47s/it, train_loss=0.294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fitting\n",
      "  Fit complete: 11.28059196472168 sec elapsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval models:   0%|                                                                     | 0/26 [00:05<?, ?it/s]\n",
      "[W 2023-08-17 18:08:03,273] Trial 0 failed with parameters: {'num_subs': 45, 'num_inh': 0.69, 'proj_filter_width': 15, 'proj_NLtype': 'relu', 'num_iter': 7, 'iter_filter_width': 15} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mattjac/anaconda3/envs/pytorch2/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_4021331/2926880145.py\", line 121, in objective_iter\n",
      "    LLs = cnn.eval_models(data, data_inds=data.val_blks, batch_size=5)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mattjac/projects/mattjac/v1/coremodel/../NDNT/NDNT.py\", line 782, in eval_models\n",
      "    pred = self(data_sample)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mattjac/anaconda3/envs/pytorch2/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mattjac/projects/mattjac/v1/coremodel/../NDNT/NDNT.py\", line 170, in forward\n",
      "    net_ins, net_outs = self.compute_network_outputs( Xs )\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mattjac/projects/mattjac/v1/coremodel/../NDNT/NDNT.py\", line 152, in compute_network_outputs\n",
      "    net_outs.append( self.networks[ii]( net_ins[-1] ) )\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mattjac/anaconda3/envs/pytorch2/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mattjac/projects/mattjac/v1/coremodel/../NDNT/networks.py\", line 337, in forward\n",
      "    x = layer(x)\n",
      "        ^^^^^^^^\n",
      "  File \"/home/mattjac/anaconda3/envs/pytorch2/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mattjac/projects/mattjac/v1/coremodel/../NDNT/modules/layers/reslayers.py\", line 168, in forward\n",
      "    y = F.conv2d(\n",
      "        ^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2023-08-17 18:08:03,276] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SortKey, Stats\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m profile:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39moptimize(objective_iter,\u001b[38;5;250m \u001b[39mn_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     (\n\u001b[1;32m     15\u001b[0m         Stats(profile)\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;241m.\u001b[39mstrip_dirs()\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;241m.\u001b[39msort_stats(SortKey\u001b[38;5;241m.\u001b[39mCALLS)\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;241m.\u001b[39mprint_stats()\n\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# dump the final study\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.11/site-packages/optuna/study/study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     _optimize(\n\u001b[1;32m    444\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    445\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    446\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    447\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    448\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    449\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    450\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    451\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    452\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    453\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[31], line 121\u001b[0m, in \u001b[0;36mobjective_iter\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    118\u001b[0m cnn \u001b[38;5;241m=\u001b[39m make_model_iter(trial)\n\u001b[1;32m    120\u001b[0m cnn\u001b[38;5;241m.\u001b[39mfit(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madam_parsT, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 121\u001b[0m LLs \u001b[38;5;241m=\u001b[39m cnn\u001b[38;5;241m.\u001b[39meval_models(data, data_inds\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mval_blks, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    123\u001b[0m null_adjusted_LLs \u001b[38;5;241m=\u001b[39m expts\u001b[38;5;241m.\u001b[39mLLsNULL\u001b[38;5;241m-\u001b[39mLLs\n\u001b[1;32m    125\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m Model(cnn, null_adjusted_LLs, trial)\n",
      "File \u001b[0;32m~/projects/mattjac/v1/coremodel/../NDNT/NDNT.py:782\u001b[0m, in \u001b[0;36mNDN.eval_models\u001b[0;34m(self, data, data_inds, bits, null_adjusted, speckledXV, train_val, batch_size, num_workers, **kwargs)\u001b[0m\n\u001b[1;32m    780\u001b[0m         data_sample[dsub] \u001b[38;5;241m=\u001b[39m data_sample[dsub]\u001b[38;5;241m.\u001b[39mto(d)\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 782\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(data_sample)\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m speckledXV:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m train_val \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/mattjac/v1/coremodel/../NDNT/NDNT.py:170\u001b[0m, in \u001b[0;36mNDN.forward\u001b[0;34m(self, Xs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, Xs):\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This applies the forwards of each network in sequential order.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m    The tricky thing is concatenating multiple-input dimensions together correctly.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    Note that the external inputs is actually in principle a list of inputs\"\"\"\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     net_ins, net_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_network_outputs( Xs )\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# For now assume its just one output, given by the first value of self.ffnet_out\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m net_outs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffnet_out[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m~/projects/mattjac/v1/coremodel/../NDNT/NDNT.py:152\u001b[0m, in \u001b[0;36mNDN.compute_network_outputs\u001b[0;34m(self, Xs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetworks[ii]\u001b[38;5;241m.\u001b[39mffnets_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# then getting external input\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     net_ins\u001b[38;5;241m.\u001b[39mappend( [Xs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetworks[ii]\u001b[38;5;241m.\u001b[39mxstim_n]] )\n\u001b[0;32m--> 152\u001b[0m     net_outs\u001b[38;5;241m.\u001b[39mappend( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetworks[ii]( net_ins[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] ) )\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     in_nets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetworks[ii]\u001b[38;5;241m.\u001b[39mffnets_in\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/mattjac/v1/coremodel/../NDNT/networks.py:337\u001b[0m, in \u001b[0;36mScaffoldNetwork.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    334\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_input(inputs)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 337\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer(x)\n\u001b[1;32m    338\u001b[0m     nt \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39moutput_dims[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_lags_out:\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;66;03m# Need to return just first lag (lag0) -- 'chomp'\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/mattjac/v1/coremodel/../NDNT/modules/layers/reslayers.py:168\u001b[0m, in \u001b[0;36mIterLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    160\u001b[0m         y \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    161\u001b[0m             x, \u001b[38;5;66;03m# we do our own padding\u001b[39;00m\n\u001b[1;32m    162\u001b[0m             w\u001b[38;5;241m.\u001b[39mview([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolded_dims, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_dims[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_dims[\u001b[38;5;241m2\u001b[39m]]),\n\u001b[1;32m    163\u001b[0m             bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    164\u001b[0m             stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    165\u001b[0m             dilation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;66;03m# functional pads since padding is simple\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m         y \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    169\u001b[0m             x, \n\u001b[1;32m    170\u001b[0m             w\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolded_dims, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_dims[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_dims[\u001b[38;5;241m2\u001b[39m]]),\n\u001b[1;32m    171\u001b[0m             padding\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npads[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npads[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    172\u001b[0m             bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    173\u001b[0m             stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    174\u001b[0m             dilation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Nonlinearity\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNL \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m&\u001b[39m  (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLN_reverse):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create study\n",
    "study = optuna.create_study(direction='maximize',\n",
    "                            study_name='Four datasets w/o initializing LGN weights')\n",
    "\n",
    "# enqueue initial parameters\n",
    "study.enqueue_trial(val_map)\n",
    "\n",
    "# run the study\n",
    "from cProfile import Profile\n",
    "from pstats import SortKey, Stats\n",
    "\n",
    "with Profile() as profile:\n",
    "    print(f\"{study.optimize(objective_iter, n_trials=1) = }\")\n",
    "    (\n",
    "        Stats(profile)\n",
    "        .strip_dirs()\n",
    "        .sort_stats(SortKey.CALLS)\n",
    "        .print_stats()\n",
    "    )\n",
    "\n",
    "# dump the final study\n",
    "with open(folder_name+'/study.pkl', 'wb') as f:\n",
    "    pickle.dump(study, f)\n",
    "\n",
    "# print the best trial\n",
    "print(study.best_trial.number, study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aeb5dd67496e9d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
